import sys
sys.path.append('.')

import os
import json
import logging
import asyncio
import sqlite3
import queue
import re
import random
from datetime import datetime
from dataclasses import dataclass
from typing import Dict, List, Optional
from fastapi import FastAPI, HTTPException, Response, UploadFile, File, Form
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pathlib import Path
from groq import AsyncGroq
from dotenv import load_dotenv
import whisper
from gtts import gTTS
import tempfile

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# T/F ì„±í–¥ ë¶„ì„ í•¨ìˆ˜ë“¤ (ëª¨ë“ˆí™” ì´ì „ ìƒíƒœ)
def analyze_tf_tendency(text: str) -> float:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ T, 100ì— ê°€ê¹Œìš¸ìˆ˜ë¡ F ì„±í–¥ì…ë‹ˆë‹¤.
    """
    text = text.lower()
    logger.info(f"ğŸ” Fallback ë¶„ì„ ì‹œì‘: {text[:50]}...")

    # ì‚¬ê³ í˜•(T) ê°•í•œ ë¬´ì‹¬/ë‹¨ì •/ê°ê´€ì  í‘œí˜„ íŒ¨í„´ (í™•ì‹¤í•œ ì‚¬ê³ í˜•)
    t_strong_patterns = [
        r"ì–´ì©Œë¼ê³ ", r"ìƒê´€ì—†ì–´", r"ì•Œì•„ì„œ í•´", r"ë‚´ ì•Œ ë°” ì•„ëƒ", r"ê·¸ê²Œ ë‚˜ë‘ ë¬´ìŠ¨ ìƒê´€ì´ì•¼",
        r"ë„¤ ë§ˆìŒëŒ€ë¡œ í•´", r"ë‚´ê°€ ë­˜", r"ê·¸ê±´ ë„¤ ë¬¸ì œì•¼", r"ê·¸ê±´ ì¤‘ìš”í•˜ì§€ ì•Šì•„"
    ]
    t_strong_count = sum(len(re.findall(pattern, text)) for pattern in t_strong_patterns)
    if t_strong_count > 0:
        score = max(15, 30 - (t_strong_count - 1) * 5)
        return float(score)

    # ì‹¸ê°€ì§€ ì—†ëŠ”(ê³µê° ì—†ëŠ” í‰ëª…/ë¬´ì‹¬) íŒ¨í„´ (ì‚´ì§ T)
    t_rude_patterns = [
        r"ëª°ë¼", r"ë”±íˆ", r"ë³„ ìƒê° ì—†ì–´", r"ì‹ ê²½ ì•ˆ ì¨", r"ê´€ì‹¬ ì—†ì–´", r"ê·¸ëƒ¥ ê·¸ë˜", r"ê¸€ì„", r"ìŒ[.\.\,\!\?â€¦]*$", r"ë³„ë¡œì•¼"
    ]
    t_rude_count = sum(len(re.findall(pattern, text)) for pattern in t_rude_patterns)
    if t_rude_count > 0:
        # í‰ëª…/ë¬´ì‹¬ íŒ¨í„´ì´ ê°ì§€ë˜ë©´ 35~45ì (ì‚´ì§ T)
        score = max(35, 45 - (t_rude_count - 1) * 3)
        return float(score)

    # 1. í‚¤ì›Œë“œ(í•µì‹¬/ì•½í•œ) ë° ê°€ì¤‘ì¹˜
    t_keywords_strong = [
        'ë…¼ë¦¬', 'ë¶„ì„', 'íŒë‹¨', 'íš¨ìœ¨', 'ê°ê´€', 'ì‚¬ì‹¤', 'ì¦ê±°', 'í•©ë¦¬', 'ì´ì„±', 'ì²´ê³„',
        'ì •í™•', 'ëª…í™•', 'ì¼ê´€', 'ë°ì´í„°', 'í†µê³„', 'ì¸¡ì •',
        'ë§ë‹¤', 'í‹€ë ¸ë‹¤', 'ì •ë‹µ', 'í™•ì‹¤', 'ëª…ë°±', 'ë¶„ëª…', 'í™•ì¸',
        'ê²€í† ', 'í‰ê°€', 'ê¸°ì¤€', 'ì¡°ê±´', 'í•´ê²°', 'ê°œì„ ',
        'ìµœì ', 'íš¨ê³¼', 'ê²°ì •', 'ì„ íƒ', 'ìš°ì„ ìˆœìœ„', 'ì¤‘ìš”ë„',
        'ë¶ˆê°€ëŠ¥', 'ë¬¸ì œ', 'í•´ë‹µ', 'ë‹µ', 'ë°˜ë“œì‹œ', 'ë¬´ì¡°ê±´', 'ì²´í¬', 'ì‹¤ìš©ì ', 'ê³„ì‚°'
    ]
    t_keywords_weak = [
        'ê³„íš', 'ì „ëµ', 'ëª©í‘œ', 'ì„±ê³¼', 'ë°©ë²•', 'í•´ì•¼', 'í•´ì•¼ì§€', 'í•˜ì', 'ëë‹¤', 'ì•ˆ ë¼', 'ì•ˆ ë¨',
        'í™•ì‹¤íˆ', 'ë¶„ëª…íˆ', 'ì •í™•íˆ', 'ë‹¹ì—°íˆ', 'ë°”ë¡œ', 'ë¨¼ì €', 'ìš°ì„ ', 'ì¼ë‹¨', 'ì •ë¦¬', 'íš¨ê³¼ì ', 'íš¨ìœ¨ì ',
        'ê°„ë‹¨', 'ë³µì¡', 'ê°€ëŠ¥', 'ëë‹¤', 'ìš°ì„ ', 'ì¼ë‹¨', 'í¸í•´', 'í¸ë¦¬', 'ì‰½ë‹¤', 'ì–´ë µë‹¤', 'ì‹œê°„', 'ê°€ê²©', 'ë¹„ìš©'
    ]
    f_keywords_strong = [
        'ê°ì •', 'ë§ˆìŒ', 'ê³µê°', 'ë°°ë ¤', 'ì´í•´', 'ì¡°í™”', 'í˜‘ë ¥', 'ê´€ê³„', 'ì†Œí†µ', 'ì¹œë°€',
        'ê°€ì¹˜', 'ì˜ë¯¸', 'ë„ë•', 'ìœ¤ë¦¬', 'ì§€ì›', 'ê²©ë ¤', 'í–‰ë³µ', 'ìŠ¬í”„', 'ê±±ì •', 'ë¯¸ì•ˆ', 'ê³ ë§ˆ', 'ì†Œì¤‘', 'ì‚¬ë‘',
        'ë”°ëœ»', 'í¬ê·¼', 'ì•„ëŠ‘', 'í¸ì•ˆ', 'ì•ˆì‹¬', 'ë“ ë“ ', 'ê¸°ë¶„', 'ëŠë‚Œ', 'ë§ˆìŒê°€ì§', 'ì‹¬ì •',
        'í•¨ê»˜', 'ê°™ì´', 'ì„œë¡œ', 'ìš°ë¦¬ ëª¨ë‘', 'ì¹œêµ¬', 'ê°€ì¡±', 'ì‚¬ëŒë“¤', 'ë™ë£Œë“¤',
        'ì˜ˆë»', 'ê·€ì—¬ì›Œ', 'ì°©í•´', 'ë©‹ì ¸', 'ì¢‹ì•„í•´', 'ì‹«ì–´í•´'
    ]
    f_keywords_weak = [
        'ê¸°ë»', 'ì¦ê±°ì›Œ', 'ì‹ ë‚˜', 'í–‰ë³µí•´', 'ë§Œì¡±', 'ë¿Œë“¯', 'ì†ìƒ', 'ì§œì¦', 'í™”ë‚˜', 'ë‹µë‹µ', 'ë¶ˆì•ˆ', 'ì‹ ê²½ ì“°ì—¬',
        'ìš°ë¦¬', 'ë‹¤í•¨ê»˜', 'í•¨ê»˜ í•˜ì', 'ê°™ì´ í•˜ì', 'ë§ˆìŒì—', 'ë”°ëœ»', 'í¬ê·¼', 'ë³´ê³  ì‹¶ì–´', 'ë§Œë‚˜ê³  ì‹¶ì–´', 'í•˜ê³  ì‹¶ì–´'
    ]

    # ê°€ì¤‘ì¹˜ ì ìš© ì¹´ìš´íŠ¸
    t_count = sum(2 for keyword in t_keywords_strong if keyword in text) + sum(1 for keyword in t_keywords_weak if keyword in text)
    f_count = sum(2 for keyword in f_keywords_strong if keyword in text) + sum(1 for keyword in f_keywords_weak if keyword in text)

    # íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ë¶„ì„
    f_patterns = [
        r'ì–´ë–»ê²Œ ìƒê°|ì–´ë–¤ ëŠë‚Œ|ê´œì°®ì„ê¹Œ|ì–´ë–¨ê¹Œ|ì¢‹ì„ ê²ƒ ê°™|ë‚˜ì  ê²ƒ ê°™',
        r'í•˜ë©´ ì¢‹ê² |í–ˆìœ¼ë©´|ì¸ ê²ƒ ê°™|ëŠë‚Œì´|ê¸°ë¶„ì´',
        r'í•¨ê»˜|ê°™ì´|ì„œë¡œ|ìš°ë¦¬|ëª¨ë‘|ë‹¤í•¨ê»˜',
        r'ë¯¸ì•ˆ|ê³ ë§ˆì›Œ|ì‚¬ë‘|ì†Œì¤‘|ì•„ê»´|ì±™ê¸°',
        r'ê³µê°|ì´í•´|ìœ„ë¡œ|ê²©ë ¤|ì‘ì›',
        r'ì¢‹ì•„|ì‹«ì–´|ì˜ˆë»|ê·€ì—¬ì›Œ|ì¬ë°Œ|ì§€ë£¨',
        r'ê¸°ë¶„ ì¢‹|ëŠë‚Œ ì¢‹|ë§ˆìŒì—|ë”°ëœ»|í¬ê·¼',
        r'í•˜ê³  ì‹¶ì–´|ê°€ê³  ì‹¶ì–´|ë³´ê³  ì‹¶ì–´|ë§Œë‚˜ê³  ì‹¶ì–´',
        r'ê°™ì´ í•˜ì|í•¨ê»˜ í•˜ì|ìš°ë¦¬ ëª¨ë‘|ë‹¤ ê°™ì´'
    ]
    t_patterns = [
        r'í•´ì•¼ í•œë‹¤|í•´ì•¼ì§€|í•˜ì|í•˜ë©´ ë¼|ë˜ë©´|ì•ˆ ë˜ë©´',
        r'ë‹¹ì—°íˆ|ì •í™•íˆ|ë§ë‹¤|í‹€ë ¸ë‹¤|ì˜³ë‹¤|ê·¸ë¥´ë‹¤|í™•ì‹¤íˆ|ë¶„ëª…íˆ',
        r'íš¨ìœ¨ì |ì²´ê³„ì |ë…¼ë¦¬ì |í•©ë¦¬ì |ê°ê´€ì ',
        r'ì¤‘ìš”í•œ ê±´|í•µì‹¬ì€|ë¬¸ì œëŠ”|í•´ê²°ì±…ì€|ë°©ë²•ì€',
        r'ë¨¼ì €|ìš°ì„ |ì°¨ë¡€ë¡œ|ë‹¨ê³„ë³„ë¡œ|ê³„íšì ìœ¼ë¡œ',
        r'ê·¸ëƒ¥|ë°”ë¡œ|ë¹¨ë¦¬|ì¦‰ì‹œ|ì¼ë‹¨|ìš°ì„ ',
        r'ì•ˆ ë¼|ì•ˆ ë¨|ë˜ë„¤|ëë‹¤|ê°€ëŠ¥|ë¶ˆê°€ëŠ¥',
        r'ì‰½ë‹¤|ì–´ë µë‹¤|ê°„ë‹¨|ë³µì¡|í¸í•´|í¸ë¦¬',
        r'ê³„ì‚°|ë¹„ìš©|ê°€ê²©|ì‹œê°„|íš¨ê³¼|ì‹¤ìš©'
    ]
    f_pattern_count = sum(len(re.findall(pattern, text)) for pattern in f_patterns)
    t_pattern_count = sum(len(re.findall(pattern, text)) for pattern in t_patterns)
    
    soft_tone = len(re.findall(r'ê²ƒ ê°™ì•„|ì¸ ë“¯|ì•„ë§ˆ|í˜¹ì‹œ|ë©´ ì–´ë–¨ê¹Œ|í•˜ë©´ ì¢‹ê² |~ì¸ê°€|~í• ê¹Œ|~ì§€ ì•Šì„ê¹Œ', text))
    firm_tone = len(re.findall(r'ë°˜ë“œì‹œ|ë¬´ì¡°ê±´|í™•ì‹¤íˆ|ë‹¹ì—°íˆ|ëª…ë°±íˆ|ë¶„ëª…íˆ|í•´ì•¼|í•˜ì|ëœë‹¤|ì•ˆ ëœë‹¤', text))
    question_suggestion = len(re.findall(r'\?|í• ê¹Œ|ì–´ë–¨ê¹Œ|ì¢‹ì„ê¹Œ|ì–´ë•Œ|ê´œì°®ì„ê¹Œ', text))
    statement_command = len(re.findall(r'ë‹¤\.|ì´ë‹¤\.|í•˜ì\.|í•´ì•¼\.|ëœë‹¤\.|ì•ˆ ëœë‹¤\.', text))
    
    total_keywords = t_count + f_count
    total_patterns = f_pattern_count + t_pattern_count  
    total_tone = soft_tone + firm_tone
    total_structure = question_suggestion + statement_command
    
    # 2. í‚¤ì›Œë“œ ì ìˆ˜(ê°€ì¤‘ì¹˜ ë°˜ì˜)
    if total_keywords == 0:
        keyword_score = 50
    else:
        t_ratio = t_count / total_keywords if total_keywords > 0 else 0
        f_ratio = f_count / total_keywords if total_keywords > 0 else 0
        if t_ratio > f_ratio:
            intensity = min(t_count, 4)
            keyword_score = 25 - (intensity * 7)  # ê¸°ì¡´ 30ì—ì„œ 25ë¡œ, ê°•ë„ë³„ -7ì ì”©
        elif f_ratio > t_ratio:
            intensity = min(f_count, 4)
            keyword_score = 75 + (intensity * 7)  # ê¸°ì¡´ 70ì—ì„œ 75ë¡œ, ê°•ë„ë³„ +7ì ì”©
        else:
            keyword_score = 50
    
    # 3. íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ì ìˆ˜(ë™ì /ì• ë§¤ì‹œ ê°€ì¤‘ì¹˜ ì¦ê°€)
    if total_patterns == 0:
        pattern_score = 50
    else:
        t_pattern_ratio = t_pattern_count / total_patterns
        f_pattern_ratio = f_pattern_count / total_patterns
        if t_pattern_ratio > f_pattern_ratio:
            intensity = min(t_pattern_count, 3)
            pattern_score = 30 - (intensity * 5)
        elif f_pattern_ratio > t_pattern_ratio:
            intensity = min(f_pattern_count, 3)
            pattern_score = 70 + (intensity * 5)
        else:
            pattern_score = 50
    
    if total_tone == 0:
        tone_score = 50
    else:
        if firm_tone > soft_tone:
            intensity = min(firm_tone, 2)
            tone_score = 25 - (intensity * 5)
        elif soft_tone > firm_tone:
            intensity = min(soft_tone, 2)
            tone_score = 75 + (intensity * 5)
        else:
            tone_score = 50
    
    if total_structure == 0:
        structure_score = 50
    else:
        if statement_command > question_suggestion:
            structure_score = 30
        elif question_suggestion > statement_command:
            structure_score = 70
        else:
            structure_score = 50
    
    text_length = len(text.replace(' ', ''))
    # ë™ì /ì• ë§¤í• ìˆ˜ë¡ íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ê°€ì¤‘ì¹˜ ì¦ê°€
    if total_keywords == 0 or abs(t_count - f_count) <= 2:
        keyword_weight = 0.25
        pattern_weight = 0.3
        tone_weight = 0.25
        structure_weight = 0.2
    elif text_length < 15:
        keyword_weight = 0.5
        pattern_weight = 0.2  
        tone_weight = 0.15
        structure_weight = 0.15
    elif text_length < 30:
        keyword_weight = 0.45
        pattern_weight = 0.25
        tone_weight = 0.15
        structure_weight = 0.15
    elif text_length < 60:
        keyword_weight = 0.4
        pattern_weight = 0.3
        tone_weight = 0.2
        structure_weight = 0.1
    else:
        keyword_weight = 0.35
        pattern_weight = 0.35
        tone_weight = 0.25
        structure_weight = 0.05
    
    final_score = (keyword_score * keyword_weight + 
                   pattern_score * pattern_weight + 
                   tone_score * tone_weight +
                   structure_score * structure_weight)
    
    # ê°•í•œ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
    strong_t_words = ['ë‹¹ì—°', 'í™•ì‹¤', 'ë§ë‹¤', 'í‹€ë ¸', 'í•´ì•¼', 'ëª…ë°±', 'ë¶„ëª…', 'í™•ì‹¤íˆ']
    strong_f_words = ['ì‚¬ë‘', 'ì†Œì¤‘', 'ë°°ë ¤', 'ê³µê°', 'ë§ˆìŒ', 'ê°ì •']
    strong_t = sum(1 for word in strong_t_words if word in text)
    strong_f = sum(1 for word in strong_f_words if word in text)
    if strong_t > strong_f and strong_t > 0:
        bonus = min(strong_t * 3, 8)
        final_score = max(final_score - bonus, 20)
    elif strong_f > strong_t and strong_f > 0:
        bonus = min(strong_f * 3, 8)
        final_score = min(final_score + bonus, 80)
    
    final_result = min(max(final_score, 15), 85)
    logger.info(f"ğŸ” Fallback ë¶„ì„ ì™„ë£Œ: {final_result}ì ")
    return final_result


def generate_f_friendly_response(question: str, answer: str, score: float) -> str:
    """
    F ì„±í–¥ ìƒëŒ€ì—ê²Œ ë” íš¨ê³¼ì ì¸ ë‹µë³€ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """
    import random
    
    def highlight_tip(tip):
        return f"<span style='font-size:1.2em;color:#ff6600;font-weight:bold'>{tip}</span>"
    
    f_tips_strong = [
        highlight_tip("ìƒëŒ€ë°©ì˜ ì…ì¥ì—ì„œ í•œ ë²ˆ ë” ìƒê°í•´ë³´ë©´ ì–´ë–¨ê¹Œìš”?"),
        highlight_tip("ìƒëŒ€ê°€ í˜ë“¤ì–´í•  ë•Œ ë¨¼ì € ê³µê°ì˜ ë§ì„ ê±´ë„¤ë³´ì„¸ìš”."),
        highlight_tip("ìƒëŒ€ì˜ ê°ì •ì„ ë¨¼ì € ì¸ì •í•´ì£¼ëŠ” í•œë§ˆë””ê°€ í° í˜ì´ ë©ë‹ˆë‹¤."),
        highlight_tip("ìƒëŒ€ê°€ ë‚´ ë§ì„ ë“£ê³  ì–´ë–¤ ê¸°ë¶„ì¼ì§€ ìƒìƒí•´ë³´ì„¸ìš”."),
        highlight_tip("ìƒëŒ€ë°©ì´ ìœ„ë¡œë°›ì„ ìˆ˜ ìˆë„ë¡ ë”°ëœ»í•˜ê²Œ í‘œí˜„í•´ë³´ì„¸ìš”.")
    ]
    
    f_tips_mild = [
        highlight_tip("ì¡°ê¸ˆ ë” ë¶€ë“œëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."),
        highlight_tip("ìƒëŒ€ë°©ì˜ ê¸°ë¶„ì„ ë¨¼ì € ë¬¼ì–´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"),
        highlight_tip("í•¨ê»˜ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ëŠ” ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”."),
        highlight_tip("ìƒëŒ€ë°©ì˜ ì˜ê²¬ì„ ë¨¼ì € ë“£ê³  ë°˜ì‘í•´ë³´ì„¸ìš”."),
        highlight_tip("ê°ì •ì  ê³µê°ì„ ë¨¼ì € í‘œí˜„í•´ë³´ì„¸ìš”.")
    ]
    
    # ì ìˆ˜ì— ë”°ë¥¸ íŒ ì„ íƒ
    if score < 30:  # ê°•í•œ T
        tip = random.choice(f_tips_strong)
    elif score < 45:  # T
        tip = random.choice(f_tips_strong + f_tips_mild)
    else:  # ê· í˜•ì 
        tip = random.choice(f_tips_mild)
    
    # ëŒ€ì•ˆ ë‹µë³€ ìƒì„±
    alternatives = get_f_friendly_alternatives()
    alternative = random.choice(alternatives) if alternatives else "ìƒëŒ€ë°©ì˜ ê°ì •ì„ ê³ ë ¤í•œ ë‹µë³€ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    
    return f"{tip}<br><br><b>ëŒ€ì•ˆ ë‹µë³€:</b> {alternative}"


def get_f_friendly_alternatives():
    """F ì„±í–¥ ì¹œí™”ì  ëŒ€ì•ˆ ë‹µë³€ë“¤"""
    return [
        "ìƒëŒ€ë°©ì˜ ê¸°ë¶„ì„ ë¨¼ì € ë¬¼ì–´ë³´ê³  ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”.",
        "í•¨ê»˜ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?",
        "ìƒëŒ€ë°©ì˜ ì…ì¥ì—ì„œ í•œ ë²ˆ ë” ìƒê°í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”.",
        "ê°ì •ì  ê³µê°ì„ ë¨¼ì € í‘œí˜„í•œ í›„ ë…¼ë¦¬ì  ì„¤ëª…ì„ ë”í•´ë³´ì„¸ìš”.",
        "ìƒëŒ€ë°©ì˜ ì˜ê²¬ì„ ë¨¼ì € ë“£ê³  ë°˜ì‘í•´ë³´ì„¸ìš”.",
        "ë”°ëœ»í•˜ê³  ë°°ë ¤í•˜ëŠ” ë§ˆìŒìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”.",
        "ìƒëŒ€ë°©ì´ ìœ„ë¡œë°›ì„ ìˆ˜ ìˆë„ë¡ í‘œí˜„í•´ë³´ì„¸ìš”.",
        "í•¨ê»˜ ê³ ë¯¼í•˜ê³  í•´ê²°í•´ë³´ëŠ” ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”."
    ]


def get_t_strong_ment():
    """T ì„±í–¥ ê°•í•œ ë©˜íŠ¸ë“¤"""
    return [
        "ë…¼ë¦¬ì ì´ê³  ê°ê´€ì ì¸ íŒë‹¨ì„ ì„ í˜¸í•˜ëŠ” ì„±í–¥ì´ë„¤ìš”.",
        "íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ì¤‘ì‹œí•˜ëŠ” ì‚¬ê³ ë°©ì‹ì„ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”.",
        "ì²´ê³„ì ì´ê³  ë¶„ì„ì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
        "ì‚¬ì‹¤ê³¼ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ íŒë‹¨ì„ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ì‹œë„¤ìš”.",
        "í•©ë¦¬ì ì´ê³  ì´ì„±ì ì¸ ì‚¬ê³ ë¥¼ ì„ í˜¸í•˜ëŠ” ì„±í–¥ì…ë‹ˆë‹¤."
    ]


def get_t_mild_ment():
    """T ì„±í–¥ ì•½í•œ ë©˜íŠ¸ë“¤"""
    return [
        "ë…¼ë¦¬ì  ì‚¬ê³ ë¥¼ ì„ í˜¸í•˜ì§€ë§Œ ê°ì •ë„ ê³ ë ¤í•˜ëŠ” ê· í˜•ì¡íŒ ì„±í–¥ì´ë„¤ìš”.",
        "íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ë˜ ê´€ê³„ë„ ì†Œì¤‘í•˜ê²Œ ì—¬ê¸°ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
        "ì²´ê³„ì  ì ‘ê·¼ì„ ì„ í˜¸í•˜ì§€ë§Œ ìœ ì—°ì„±ë„ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”.",
        "ì‚¬ì‹¤ì„ ì¤‘ì‹œí•˜ë˜ ì‚¬ëŒì˜ ê°ì •ë„ ë°°ë ¤í•˜ëŠ” ì„±í–¥ì…ë‹ˆë‹¤.",
        "í•©ë¦¬ì  ì‚¬ê³ ë¥¼ ì„ í˜¸í•˜ì§€ë§Œ ê³µê°ëŠ¥ë ¥ë„ ë›°ì–´ë‚˜ì‹  ê²ƒ ê°™ì•„ìš”."
    ]


def generate_ai_questions_real(prompt: str) -> str:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # ê°„ë‹¨í•œ fallback êµ¬í˜„
        return "AI ì§ˆë¬¸ ìƒì„± ê¸°ëŠ¥ì€ í˜„ì¬ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def generate_fallback_questions(count: int = 5) -> List[str]:
    """ê¸°ë³¸ ì§ˆë¬¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    questions = [
        "ì¹œêµ¬ê°€ ì‹¤ìˆ˜ë¡œ ë‚´ ë¬¼ê±´ì„ ë§ê°€ëœ¨ë ¸ì„ ë•Œ ì–´ë–»ê²Œ ë°˜ì‘í•˜ì‹œë‚˜ìš”?",
        "ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë¦´ ë•Œ ì–´ë–¤ ë°©ì‹ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?",
        "ìƒëŒ€ë°©ì´ ê°ì •ì ìœ¼ë¡œ í˜ë“¤ì–´í•  ë•Œ ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì‹œë‚˜ìš”?",
        "ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•Œ í•´ê²° ë°©ë²•ì„ ì°¾ëŠ” ë°©ì‹ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë‹¤ë¥¸ ì‚¬ëŒê³¼ ì˜ê²¬ì´ ë‹¤ë¥¼ ë•Œ ì–´ë–»ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì‹œë‚˜ìš”?",
        "ìƒˆë¡œìš´ í™˜ê²½ì— ì ì‘í•  ë•Œ ì–´ë–¤ ë§ˆìŒê°€ì§ìœ¼ë¡œ ì„í•˜ì‹œë‚˜ìš”?",
        "ìƒëŒ€ë°©ì˜ ì‹¤ìˆ˜ë¥¼ ì§€ì í•´ì•¼ í•  ë•Œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í•˜ì‹œë‚˜ìš”?",
        "ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©ì—ì„œ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ë§ˆìŒì„ ë‹¤ì¡ìœ¼ì‹œë‚˜ìš”?",
        "ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ì¡°ì–¸ì„ ì¤„ ë•Œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í•˜ì‹œë‚˜ìš”?",
        "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ìƒê²¼ì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œë‚˜ìš”?"
    ]
    return questions[:count]


def generate_final_analysis(results: List[Dict]) -> Dict:
    """ì „ì²´ ì§ˆë¬¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."""
    if not results:
        return {
            "overall_tendency": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "personality_analysis": "",
            "communication_strategy": "",
            "strengths": [],
            "growth_areas": [],
            "keyword_analysis": {}
        }
    
    # ì „ì²´ í‰ê·  ì ìˆ˜ ê³„ì‚°
    total_score = sum(r['score'] for r in results) / len(results)
    
    # ì ìˆ˜ ë¶„í¬ ë¶„ì„
    t_responses = sum(1 for r in results if r['score'] < 40)
    neutral_responses = sum(1 for r in results if 40 <= r['score'] <= 60) 
    f_responses = sum(1 for r in results if r['score'] > 60)
    
    # ì „ì²´ ì„±í–¥ íŒë‹¨
    if total_score < 30:
        overall_tendency = "ê°•í•œ T(ì‚¬ê³ í˜•) ì„±í–¥"
        tendency_desc = "ë…¼ë¦¬ì ì´ê³  ê°ê´€ì ì¸ íŒë‹¨ì„ ì„ í˜¸í•˜ëŠ”"
    elif total_score < 45:
        overall_tendency = "T(ì‚¬ê³ í˜•) ì„±í–¥"
        tendency_desc = "í•©ë¦¬ì  ì‚¬ê³ ë¥¼ ì¤‘ì‹œí•˜ëŠ”"
    elif total_score < 55:
        overall_tendency = "T-F ê· í˜•"
        tendency_desc = "ë…¼ë¦¬ì™€ ê°ì •ì˜ ê· í˜•ì´ ì¡íŒ"
    elif total_score < 70:
        overall_tendency = "F(ê°ì •í˜•) ì„±í–¥"
        tendency_desc = "ê°ì •ê³¼ ê´€ê³„ë¥¼ ì¤‘ì‹œí•˜ëŠ”"
    else:
        overall_tendency = "ê°•í•œ F(ê°ì •í˜•) ì„±í–¥"
        tendency_desc = "ê¹Šì€ ê³µê°ê³¼ ë°°ë ¤ì‹¬ì„ ê°€ì§„"
    
    # ì„±ê²© ë¶„ì„
    consistency = 100 - (max([r['score'] for r in results]) - min([r['score'] for r in results]))
    if consistency > 80:
        consistency_desc = "ì¼ê´€ì„±ì´ ë§¤ìš° ë†’ê³  ì•ˆì •ëœ"
    elif consistency > 60:
        consistency_desc = "ì–´ëŠ ì •ë„ ì¼ê´€ëœ"
    else:
        consistency_desc = "ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ëŠ”"
    
    personality_analysis = f"""
ë‹¹ì‹ ì€ {tendency_desc} {consistency_desc} ì„±í–¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. 

{len(results)}ê°œì˜ ì§ˆë¬¸ ì¤‘ T ì„±í–¥ ë‹µë³€ì´ {t_responses}ê°œ, ê· í˜•ì  ë‹µë³€ì´ {neutral_responses}ê°œ, F ì„±í–¥ ë‹µë³€ì´ {f_responses}ê°œë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. 
ì „ì²´ì ìœ¼ë¡œ {total_score:.1f}ì ìœ¼ë¡œ {overall_tendency}ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    """.strip()
    
    return {
        "overall_tendency": overall_tendency,
        "personality_analysis": personality_analysis,
        "communication_strategy": "ìƒëŒ€ë°©ì˜ ì„±í–¥ì— ë§ì¶° ëŒ€í™”ë¥¼ ì¡°ì ˆí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
        "strengths": ["ë…¼ë¦¬ì  ì‚¬ê³ ", "ê°ê´€ì  íŒë‹¨", "íš¨ìœ¨ì„± ì¤‘ì‹œ"],
        "growth_areas": ["ê°ì •ì  ê³µê°", "ê´€ê³„ ì¤‘ì‹¬ì  ì‚¬ê³ "],
        "keyword_analysis": {}
    }


def transcribe_audio_file(audio_file_path: str) -> str:
    """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        # Whisper ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹
        result = whisper.load_model("base").transcribe(audio_file_path)
        return result["text"]
    except Exception as e:
        return f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def text_to_speech(text: str, output_path: str, lang='ko-KR', voice_name='ko-KR-Chirp3-HD-Leda', gender='FEMALE', speaking_rate=1.1, pitch=0.0) -> bool:
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        # Google Cloud TTS ì‚¬ìš© (ê³ ê¸‰ ì„¤ì •)
        print(f"ğŸ” Google Cloud TTS ì‹œë„ ì¤‘... (ìŒì„±: {voice_name}, ì„±ë³„: {gender})")
        from google.cloud import texttospeech
        
        client = texttospeech.TextToSpeechClient()
        synthesis_input = texttospeech.SynthesisInput(text=text)
        
        # ì„±ë³„ ë§¤í•‘
        gender_map = {
            'MALE': texttospeech.SsmlVoiceGender.MALE,
            'FEMALE': texttospeech.SsmlVoiceGender.FEMALE,
            'NEUTRAL': texttospeech.SsmlVoiceGender.NEUTRAL
        }
        
        voice = texttospeech.VoiceSelectionParams(
            language_code=lang,
            name=voice_name,
            ssml_gender=gender_map.get(gender.upper(), texttospeech.SsmlVoiceGender.FEMALE)
        )
        
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=speaking_rate,
            pitch=pitch
        )
        
        print(f"ğŸ” Google Cloud TTS ìš”ì²­ ì¤‘...")
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        # íŒŒì¼ë¡œ ì €ì¥
        with open(output_path, 'wb') as f:
            f.write(response.audio_content)
        
        print(f"âœ… Google Cloud TTS ì„±ê³µ!")
        return True
    except Exception as e:
        print(f"âŒ Google Cloud TTS ì‹¤íŒ¨: {e}")
        print(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        # Google Cloud TTS ì‹¤íŒ¨ ì‹œ gTTSë¡œ í´ë°±
        try:
            print(f"ğŸ”„ gTTS í´ë°± ì‹œë„ ì¤‘...")
            tts = gTTS(text=text, lang='ko')
            tts.save(output_path)
            print(f"âœ… gTTS í´ë°± ì„±ê³µ!")
            return True
        except Exception as fallback_e:
            print(f"âŒ gTTS í´ë°±ë„ ì‹¤íŒ¨: {fallback_e}")
            return False


def transcribe_audio_file_enhanced(audio_file_path: str) -> Dict:
    """í–¥ìƒëœ ìŒì„± ì¸ì‹ ê¸°ëŠ¥"""
    try:
        # ê¸°ë³¸ STT ìˆ˜í–‰
        text = transcribe_audio_file(audio_file_path)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        confidence = 0.8
        if len(text.strip()) < 3:
            confidence = 0.5
        elif len(text.strip()) > 50:
            confidence = 0.9
        
        # ëŒ€ì•ˆ í…ìŠ¤íŠ¸ ìƒì„± (ê°„ë‹¨í•œ ë³€í˜•)
        alternatives = []
        if text:
            # ì¡°ì‚¬ ë³€í˜•
            alternatives.append(text.replace("ì…ë‹ˆë‹¤", "ì´ì—ìš”"))
            alternatives.append(text.replace("ì´ì—ìš”", "ì…ë‹ˆë‹¤"))
            # ë„ì–´ì“°ê¸° ë³€í˜•
            alternatives.append(text.replace(" ", ""))
        
        return {
            "text": text,
            "original_text": text,
            "confidence": confidence,
            "alternatives": alternatives[:3],  # ìµœëŒ€ 3ê°œ
            "has_alternatives": len(alternatives) > 0
        }
    except Exception as e:
        return {
            "text": f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}",
            "original_text": "",
            "confidence": 0.0,
            "alternatives": [],
            "has_alternatives": False
        }


def validate_audio_quality(audio_file_path: str) -> Dict:
    """ì˜¤ë””ì˜¤ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        import librosa
        import numpy as np
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        y, sr = librosa.load(audio_file_path, sr=None)
        duration = len(y) / sr
        
        # ê¸°ë³¸ í’ˆì§ˆ ê²€ì¦
        is_good = True
        suggestions = []
        
        # ê¸¸ì´ ê²€ì¦
        if duration < 0.5:
            is_good = False
            suggestions.append("ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 1ì´ˆ ì´ìƒ ë§ì”€í•´ì£¼ì„¸ìš”.")
        elif duration > 30:
            is_good = False
            suggestions.append("ìŒì„±ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 30ì´ˆ ì´ë‚´ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        
        # ë³¼ë¥¨ ê²€ì¦
        rms = np.sqrt(np.mean(y**2))
        if rms < 0.01:
            is_good = False
            suggestions.append("ìŒì„±ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ë” í¬ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        
        # ìƒ˜í”Œë§ ë ˆì´íŠ¸ ê²€ì¦
        if sr < 8000:
            suggestions.append("ìŒì„± í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        
        return {
            "valid": True,
            "is_good": is_good,
            "duration": duration,
            "sample_rate": sr,
            "channels": 1,
            "suggestions": suggestions
        }
        
    except Exception as e:
        # librosaê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "valid": True,
            "is_good": True,
            "duration": 0,
            "sample_rate": 0,
            "channels": 0,
            "suggestions": []
        }


def correct_sentence_with_ai_enhanced(text: str) -> Dict:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ êµì •í•©ë‹ˆë‹¤."""
    try:
        # ë¬¸ì¥ êµì • í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ë‹¤ìŒ ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•´ì£¼ì„¸ìš”.

êµì • ê·œì¹™:
1. ì˜¤íƒ€ë‚˜ ì˜ëª»ëœ ë‹¨ì–´ë¥¼ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¡œ ìˆ˜ì •
2. ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì • (ì¡°ì‚¬, ì–´ë¯¸ ë“±)
3. ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì™„ì„±
4. ì›ë˜ ì˜ë¯¸ëŠ” ë°˜ë“œì‹œ ìœ ì§€
5. êµì •ëœ ë¬¸ì¥ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)

ìŒì„± ì¸ì‹ ê²°ê³¼: "{text}"

êµì •ëœ ë¬¸ì¥:
"""
        
        # Gemini AI ì‚¬ìš©
        import google.generativeai as genai
        import os
        
        gemini_key = os.getenv('GEMINI_API_KEY')
        if not gemini_key:
            from mbti_analyzer.config.settings import settings
            gemini_key = settings.gemini_api_key
        
        if not gemini_key:
            return {
                "success": True,
                "corrected_text": text,
                "method_used": "fallback",
                "error": "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # AI ì‘ë‹µ ìƒì„±
        response = model.generate_content(prompt)
        corrected_text = response.text.strip()
        
        # êµì • ê²°ê³¼ ì •ë¦¬
        if corrected_text and isinstance(corrected_text, str):
            # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
            corrected_text = corrected_text.replace("êµì •ëœ ë¬¸ì¥:", "").strip()
            corrected_text = corrected_text.replace("êµì •:", "").strip()
            corrected_text = corrected_text.replace("ìˆ˜ì •ëœ ë¬¸ì¥:", "").strip()
            corrected_text = corrected_text.replace("ê²°ê³¼:", "").strip()
            corrected_text = corrected_text.replace("ë‹µë³€:", "").strip()
            
            # ì¤„ë°”ê¿ˆ ì •ë¦¬
            corrected_text = corrected_text.replace("\n", " ").strip()
            
            # ë”°ì˜´í‘œ ì œê±°
            corrected_text = corrected_text.strip('"').strip("'").strip()
            
            # ë¹ˆ ë¬¸ìì—´ ì²´í¬
            if not corrected_text:
                corrected_text = text
            
            return {
                "success": True,
                "corrected_text": corrected_text,
                "method_used": "ai",
                "has_changes": corrected_text != text
            }
        else:
            return {
                "success": True,
                "corrected_text": text,
                "method_used": "fallback",
                "error": "AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
            }
            
    except Exception as e:
        return {
            "success": True,
            "corrected_text": text,
            "method_used": "fallback",
            "error": str(e)
        }

# ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œì„ ìœ„í•œ ë°ì´í„° í´ë˜ìŠ¤ë“¤
@dataclass
class UserInput:
    """ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°"""
    question: str
    answer: str
    expected_score: float
    actual_score: float
    timestamp: datetime
    error: float
    is_acceptable: bool

@dataclass
class PromptVersion:
    """í”„ë¡¬í”„íŠ¸ ë²„ì „ ì •ë³´"""
    version: str
    prompt: str
    performance: Dict
    created_at: datetime

class LearningFeedbackRequest(BaseModel):
    question: str
    answer: str
    expected_score: float
    actual_score: float

class LearningStatusResponse(BaseModel):
    enabled: bool
    total_inputs: int
    acceptable_rate: float
    average_error: float
    current_version: str

# ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
class RealtimeLearningManager:
    def __init__(self):
        self.user_inputs_queue = queue.Queue()
        self.current_prompt_version = "v1.0"
        self.prompt_history = []
        self.performance_threshold = 0.6  # 60% í—ˆìš© ì˜¤ì°¨ ë‹¬ì„± ì‹œ ê°œì„ 
        self.min_inputs_for_tuning = 10   # íŠœë‹ì„ ìœ„í•œ ìµœì†Œ ì…ë ¥ ìˆ˜
        self.db_path = "learning_data.db"
        self.learning_enabled = True
        self.init_database()
        
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì‚¬ìš©ì ì…ë ¥ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_inputs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT,
                answer TEXT,
                expected_score REAL,
                actual_score REAL,
                error REAL,
                is_acceptable BOOLEAN,
                timestamp DATETIME,
                prompt_version TEXT
            )
        ''')
        
        # í”„ë¡¬í”„íŠ¸ ë²„ì „ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS prompt_versions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version TEXT,
                prompt TEXT,
                performance_data TEXT,
                created_at DATETIME
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def calculate_error(self, expected: float, actual: float) -> float:
        """ì˜¤ì°¨ ê³„ì‚°"""
        return abs(expected - actual)
    
    def is_acceptable_error(self, error: float) -> bool:
        """ì˜¤ì°¨ê°€ í—ˆìš© ë²”ìœ„(10%) ë‚´ì¸ì§€ í™•ì¸"""
        return error <= 10.0
    
    async def process_user_input(self, question: str, answer: str, expected_score: float, actual_score: float) -> Dict:
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° í•™ìŠµ"""
        if not self.learning_enabled:
            return {"success": True, "learning_disabled": True}
        
        print(f"ğŸ”„ ì‹¤ì‹œê°„ í•™ìŠµ: ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì¤‘...")
        print(f"ì§ˆë¬¸: {question}")
        print(f"ë‹µë³€: {answer}")
        print(f"ì˜ˆìƒ: {expected_score}%, ì‹¤ì œ: {actual_score}%")
        
        error = self.calculate_error(expected_score, actual_score)
        is_acceptable = self.is_acceptable_error(error)
        
        # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
        user_input = UserInput(
            question=question,
            answer=answer,
            expected_score=expected_score,
            actual_score=actual_score,
            timestamp=datetime.now(),
            error=error,
            is_acceptable=is_acceptable
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        self.save_user_input(user_input)
        
        # íì— ì¶”ê°€
        self.user_inputs_queue.put(user_input)
        
        # ì„±ëŠ¥ í‰ê°€ ë° í•„ìš”ì‹œ íŠœë‹
        await self.evaluate_and_tune_if_needed()
        
        status_emoji = "âœ…" if is_acceptable else "âŒ"
        print(f"{status_emoji} í•™ìŠµ ê²°ê³¼: ì˜¤ì°¨ {error:.1f}%")
        
        return {
            "success": True,
            "error": error,
            "is_acceptable": is_acceptable,
            "prompt_version": self.current_prompt_version
        }
    
    def save_user_input(self, user_input: UserInput):
        """ì‚¬ìš©ì ì…ë ¥ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO user_inputs 
            (question, answer, expected_score, actual_score, error, is_acceptable, timestamp, prompt_version)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            user_input.question,
            user_input.answer,
            user_input.expected_score,
            user_input.actual_score,
            user_input.error,
            user_input.is_acceptable,
            user_input.timestamp.isoformat(),
            self.current_prompt_version
        ))
        
        conn.commit()
        conn.close()
    
    def get_recent_performance(self, limit: int = 50) -> Dict:
        """ìµœê·¼ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT error, is_acceptable FROM user_inputs 
            ORDER BY timestamp DESC LIMIT ?
        ''', (limit,))
        
        results = cursor.fetchall()
        conn.close()
        
        if not results:
            return {"total": 0, "acceptable": 0, "average_error": 0.0}
        
        total = len(results)
        acceptable = sum(1 for _, is_acc in results if is_acc)
        average_error = sum(error for error, _ in results) / total
        
        return {
            "total": total,
            "acceptable": acceptable,
            "acceptable_rate": acceptable / total if total > 0 else 0,
            "average_error": average_error
        }
    
    async def evaluate_and_tune_if_needed(self):
        """ì„±ëŠ¥ í‰ê°€ ë° í•„ìš”ì‹œ íŠœë‹"""
        performance = self.get_recent_performance()
        
        if (performance["total"] >= self.min_inputs_for_tuning and 
            performance["acceptable_rate"] < self.performance_threshold):
            print(f"ğŸ”„ ì„±ëŠ¥ ê°œì„  í•„ìš”: í—ˆìš©ë¥  {performance['acceptable_rate']:.1%}")
            await self.auto_tune_prompt()
    
    async def auto_tune_prompt(self):
        """í”„ë¡¬í”„íŠ¸ ìë™ íŠœë‹"""
        print("ğŸ”„ í”„ë¡¬í”„íŠ¸ ìë™ íŠœë‹ ì‹œì‘...")
        
        # ìƒˆë¡œìš´ ë²„ì „ ìƒì„±
        new_version = f"v{len(self.prompt_history) + 1}.0"
        improved_prompt = self.generate_improved_prompt({})
        
        # í”„ë¡¬í”„íŠ¸ ì €ì¥
        self.save_prompt_version(new_version, improved_prompt)
        self.current_prompt_version = new_version
        
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {new_version}")
    
    def get_recent_user_inputs(self, limit: int = 20) -> List[UserInput]:
        """ìµœê·¼ ì‚¬ìš©ì ì…ë ¥ì„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT question, answer, expected_score, actual_score, error, is_acceptable, timestamp
            FROM user_inputs ORDER BY timestamp DESC LIMIT ?
        ''', (limit,))
        
        results = cursor.fetchall()
        conn.close()
        
        return [
            UserInput(
                question=row[0],
                answer=row[1],
                expected_score=row[2],
                actual_score=row[3],
                error=row[4],
                is_acceptable=bool(row[5]),
                timestamp=datetime.fromisoformat(row[6])
            )
            for row in results
        ]
    
    def analyze_error_patterns(self, inputs: List[UserInput]) -> Dict:
        """ì˜¤ì°¨ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤"""
        patterns = {
            "high_error_count": 0,
            "low_error_count": 0,
            "tendency_errors": 0,
            "extreme_scores": 0
        }
        
        for user_input in inputs:
            if user_input.error > 20:
                patterns["high_error_count"] += 1
            elif user_input.error < 5:
                patterns["low_error_count"] += 1
            
            if user_input.actual_score < 20 or user_input.actual_score > 80:
                patterns["extreme_scores"] += 1
        
        return patterns
    
    def generate_improved_prompt(self, error_patterns: Dict) -> str:
        """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        base_prompt = """
        MBTI T/F ì„±í–¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ì„ í‰ê°€í•˜ì„¸ìš”.

        [ë¶„ì„ ê¸°ì¤€]
        - T(Thinking): ë…¼ë¦¬ì , ê°ê´€ì , ë¶„ì„ì  ì‚¬ê³ , ì›ì¸ ë¶„ì„, ì²´ê³„ì  ì ‘ê·¼, íš¨ìœ¨ì„± ì¤‘ì‹œ, ë¬¸ì œ í•´ê²° ì§€í–¥
        - F(Feeling): ê°ì •ì , ê³µê°ì , ê´€ê³„ ì¤‘ì‹¬ì  ì‚¬ê³ , ê¸°ë¶„ ê³ ë ¤, ê³µê° í‘œí˜„, ê´€ê³„ ì¤‘ì‹œ, ê°ì •ì  ì§€ì§€
        - ì ìˆ˜: 0(ë§¤ìš° ê°•í•œ T) ~ 100(ë§¤ìš° ê°•í•œ F), 50=ê· í˜•

        [ì¶œë ¥ í˜•ì‹]
[ë¶„ì„] ë‹µë³€ìì˜ T/F ì„±í–¥ ë¶„ì„
[ê·¼ê±°] ë¶„ì„ ê·¼ê±°
[ì œì•ˆ] ê°œì„  ì œì•ˆ
        [ëŒ€ì•ˆ] ëŒ€ì•ˆ ë‹µë³€
        ì ìˆ˜: X

        ë‹µë³€: {text}
        """
        return base_prompt
    
    def save_prompt_version(self, version: str, prompt: str):
        """í”„ë¡¬í”„íŠ¸ ë²„ì „ì„ ì €ì¥í•©ë‹ˆë‹¤"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO prompt_versions (version, prompt, performance_data, created_at)
            VALUES (?, ?, ?, ?)
        ''', (version, prompt, "{}", datetime.now().isoformat()))
        
        conn.commit()
        conn.close()
        
# ì‹¤ì‹œê°„ í•™ìŠµ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
learning_manager = RealtimeLearningManager()

# ì „ì—­ í•™ìŠµ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
learning_manager = RealtimeLearningManager()

# ëª¨ë“ˆ ì—°ê²° ìƒíƒœ ë¡œê¹…
print("=== MBTI T/F Analyzer ëª¨ë“ˆ ì—°ê²° ìƒíƒœ í™•ì¸ ===")
logger.info("=== MBTI T/F Analyzer ëª¨ë“ˆ ì—°ê²° ìƒíƒœ í™•ì¸ ===")
print("âœ… ë¶„ì„ê¸° ëª¨ë“ˆ (mbti_analyzer.core.analyzer) - ì—°ê²°ë¨")
logger.info("âœ… ë¶„ì„ê¸° ëª¨ë“ˆ (mbti_analyzer.core.analyzer) - ì—°ê²°ë¨")
print("âœ… ì§ˆë¬¸ ìƒì„±ê¸° ëª¨ë“ˆ (mbti_analyzer.core.question_generator) - ì—°ê²°ë¨")
logger.info("âœ… ì§ˆë¬¸ ìƒì„±ê¸° ëª¨ë“ˆ (mbti_analyzer.core.question_generator) - ì—°ê²°ë¨")
print("âœ… ìµœì¢… ë¶„ì„ê¸° ëª¨ë“ˆ (mbti_analyzer.core.final_analyzer) - ì—°ê²°ë¨")
logger.info("âœ… ìµœì¢… ë¶„ì„ê¸° ëª¨ë“ˆ (mbti_analyzer.core.final_analyzer) - ì—°ê²°ë¨")
print("âœ… STT ëª¨ë“ˆ (mbti_analyzer.modules.stt_module) - ì—°ê²°ë¨")
logger.info("âœ… STT ëª¨ë“ˆ (mbti_analyzer.modules.stt_module) - ì—°ê²°ë¨")
print("âœ… TTS ëª¨ë“ˆ (mbti_analyzer.modules.tts_module) - ì—°ê²°ë¨")
logger.info("âœ… TTS ëª¨ë“ˆ (mbti_analyzer.modules.tts_module) - ì—°ê²°ë¨")
print("=== ëª¨ë“  ëª¨ë“ˆ ì—°ê²° ì™„ë£Œ ===")
logger.info("=== ëª¨ë“  ëª¨ë“ˆ ì—°ê²° ì™„ë£Œ ===")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ëª¨ë¸ ì´ˆê¸°í™”
print("Starting MBTI T/F Analyzer...")

# AI ëª¨ë¸ ì´ˆê¸°í™” (Gemini 1ìˆœìœ„, Groq 2ìˆœìœ„)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# Gemini ì´ˆê¸°í™”
if GEMINI_API_KEY:
    import google.generativeai as genai
    genai.configure(api_key=GEMINI_API_KEY)
    GEMINI_MODEL = genai.GenerativeModel('gemini-1.5-pro-latest')
    print("âœ… Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (1ìˆœìœ„)", flush=True)
else:
    GEMINI_MODEL = None
    print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ.", flush=True)

# Groq ì´ˆê¸°í™” (ë°±ì—…ìš©)
if GROQ_API_KEY:
    AI_CLIENT = AsyncGroq(api_key=GROQ_API_KEY)
    print("âœ… Groq AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (2ìˆœìœ„)", flush=True)
else:
    AI_CLIENT = None
    print("âš ï¸ GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ.", flush=True)

# STT ëª¨ë¸ ì´ˆê¸°í™”
print("Loading Whisper model...")
whisper_model = whisper.load_model("base")
print("Whisper model loaded successfully!")

# ì •ì  íŒŒì¼ë“¤ì„ ì„œë¹„ìŠ¤
app.mount("/static", StaticFiles(directory="."), name="static")
app.mount("/Main_pg", StaticFiles(directory="Main_pg"), name="mainpg")
app.mount("/images", StaticFiles(directory="images"), name="images")
app.mount("/fonts", StaticFiles(directory="fonts"), name="fonts")
app.mount("/Final", StaticFiles(directory="Final"), name="final")
app.mount("/Question_pg", StaticFiles(directory="Question_pg"), name="questionpg")

# ë£¨íŠ¸ ê²½ë¡œì—ì„œ HTML íŒŒì¼ë“¤ ì œê³µ
from fastapi.responses import FileResponse

@app.get("/")
async def read_index():
    logger.info("ğŸ” ë£¨íŠ¸ í˜ì´ì§€ ìš”ì²­ ì²˜ë¦¬ ì¤‘...")
    try:
        response = FileResponse("index1.html")
        logger.info("âœ… ë£¨íŠ¸ í˜ì´ì§€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë¨")
        return response
    except Exception as e:
        logger.error(f"âŒ ë£¨íŠ¸ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@app.get("/index1.html")
async def read_index1():
    return FileResponse("index1.html")

@app.get("/index2.html")
async def read_index2():
    return FileResponse("index2.html")

@app.get("/index3.html")
async def read_index3():
    return FileResponse("index3.html")

@app.get("/answer.html")
async def read_answer():
    return FileResponse("answer.html")

@app.get("/common.css")
async def read_css():
    return FileResponse("common.css")

@app.get("/favicon.ico")
async def get_favicon():
    """
    ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ìš”ì²­í•˜ëŠ” favicon.icoì— ëŒ€í•œ ì‘ë‹µ
    """
    return Response(content="", media_type="image/x-icon")

class TextRequest(BaseModel):
    text: str

class SentenceCorrectionRequest(BaseModel):
    text: str

class DetailedAnalysisRequest(BaseModel):
    question: str
    answer: str
    score: float

class AnalysisResponse(BaseModel):
    score: float
    detailed_analysis: Optional[str] = None
    reasoning: Optional[str] = None
    suggestions: Optional[list] = None
    alternative_response: Optional[str] = None

class FinalAnalysisRequest(BaseModel):
    results: List[Dict]  # [{question, answer, score}, ...]

class FinalAnalysisResponse(BaseModel):
    overall_tendency: str
    personality_analysis: str
    communication_strategy: str
    strengths: List[str]
    growth_areas: List[str]
    keyword_analysis: Dict[str, Dict[str, int]]  # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì‚¬ìš© íšŸìˆ˜

class QuestionGenerationRequest(BaseModel):
    count: Optional[int] = 5  # ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜
    difficulty: Optional[str] = "medium"  # easy, medium, hard

# generate_ai_questions_real, generate_fallback_questions, generate_ai_questions í•¨ìˆ˜ëŠ” mbti_analyzer.core.question_generatorì—ì„œ importí•˜ì—¬ ì‚¬ìš©

# analyze_tf_tendency í•¨ìˆ˜ëŠ” mbti_analyzer.core.analyzerì—ì„œ importí•˜ì—¬ ì‚¬ìš©

# generate_f_friendly_responseì™€ get_f_friendly_alternatives í•¨ìˆ˜ëŠ” mbti_analyzer.core.analyzerì—ì„œ importí•˜ì—¬ ì‚¬ìš©

# generate_final_analysis í•¨ìˆ˜ëŠ” mbti_analyzer.core.final_analyzerì—ì„œ importí•˜ì—¬ ì‚¬ìš©

def log_debug(msg):
    with open("debug.log", "a", encoding="utf-8") as f:
        f.write(msg + "\n")

@app.post("/analyze")
@app.post("/api/v1/analyze")
async def analyze_text(request: TextRequest):
    logger.info(f"ğŸ” í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘... (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(request.text)})")
    logger.info(f"ğŸ” ì…ë ¥ í…ìŠ¤íŠ¸: {request.text.strip()}")
    with open("debug.log", "a", encoding="utf-8") as f:
        f.write("[DEBUG] analyze_text í•¨ìˆ˜ ì§„ì…!\n")
    log_debug(f"[DEBUG] /analyze ìš”ì²­ ë„ì°©, AI_CLIENT: {AI_CLIENT}")
    log_debug(f"[DEBUG] ì…ë ¥ í…ìŠ¤íŠ¸: {request.text.strip()}")
    try:
        # Gemini 1ìˆœìœ„ ì‹œë„
        if GEMINI_MODEL:
            logger.info("ğŸ” Gemini AI ë¶„ì„ ì‹œë„ ì¤‘...")
            log_debug("[DEBUG] Gemini AI ë¶„ì„ ë¶„ê¸° ì§„ì… (1ìˆœìœ„)")
            log_debug("[DEBUG] Gemini AI ëª¨ë¸ ìƒíƒœ: ì •ìƒ")
            try:
                prompt = f"""
                MBTI T/F ì„±í–¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ì„ í‰ê°€í•˜ì„¸ìš”.

                [ë¶„ì„ ê¸°ì¤€]
                - T(Thinking): ë…¼ë¦¬ì , ê°ê´€ì , ë¶„ì„ì  ì‚¬ê³ , ì›ì¸ ë¶„ì„, ì²´ê³„ì  ì ‘ê·¼, íš¨ìœ¨ì„± ì¤‘ì‹œ, ë¬¸ì œ í•´ê²° ì§€í–¥
                - F(Feeling): ê°ì •ì , ê³µê°ì , ê´€ê³„ ì¤‘ì‹¬ì  ì‚¬ê³ , ê¸°ë¶„ ê³ ë ¤, ê³µê° í‘œí˜„, ê´€ê³„ ì¤‘ì‹œ, ê°ì •ì  ì§€ì§€
                - ì ìˆ˜: 0(ë§¤ìš° ê°•í•œ T) ~ 100(ë§¤ìš° ê°•í•œ F), 50=ê· í˜•

                [í•µì‹¬ ë¶„ì„ ì›ì¹™]
                1. ë‹µë³€ì˜ ì£¼ìš” ì˜ë„ì™€ í•µì‹¬ ë©”ì‹œì§€ì— ì§‘ì¤‘
                2. T ì„±í–¥ ê°•í•œ í‘œí˜„: "ë¶„ì„", "ì›ì¸", "ë…¼ë¦¬", "ì²´ê³„", "íš¨ìœ¨", "ë°©ì§€", "íŒŒì•…", "ê²°ê³¼", "í•´ê²°", "ì ‘ê·¼", "ë‹¨ê³„ë³„", "ì²´ê³„ì "
                3. F ì„±í–¥ ê°•í•œ í‘œí˜„: "ê¸°ë¶„", "ë§ˆìŒ", "ê³µê°", "í˜ë“¤", "ì•ˆíƒ€ê¹", "ê¶ê¸ˆ", "ë„ì™€", "í•¨ê»˜", "ì§€ì§€", "ìœ„ë¡œ", "ê±±ì •", "ì•ˆíƒ€ê¹"
                4. í˜¼í•© ë‹µë³€ ë¶„ì„: 
                   - T+F í˜¼í•© ë‹µë³€ì˜ ê²½ìš°: í•µì‹¬ ë©”ì‹œì§€ì˜ ë°©í–¥ì„±ì— ë”°ë¼ íŒë‹¨
                   - "ë¶„ì„í•˜ì" + "ìì±…í•˜ì§€ ë§ˆ" â†’ T ì„±í–¥ì´ ìš°ì„  (40-60ì )
                   - "í•¨ê»˜ ìƒê°í•´ë³´ì" â†’ F ì„±í–¥ì´ ìš°ì„  (60-80ì )
                5. ë§¥ë½ë³„ ì ìˆ˜ ê°€ì´ë“œ:
                   - ìˆœìˆ˜ T ì„±í–¥ (ë…¼ë¦¬ì  í•´ê²°): 20-40ì 
                   - T+F í˜¼í•© (ë¶„ì„+ê³µê°): 40-70ì   
                   - ìˆœìˆ˜ F ì„±í–¥ (ê°ì •ì  ì§€ì§€): 70-90ì 

                [ì¶œë ¥ í˜•ì‹]
                [ë¶„ì„] ë‹µë³€ìì˜ T/F ì„±í–¥ ë¶„ì„ (ì„±í–¥ ê°•ë„ì™€ ì£¼ìš” íŠ¹ì§• ëª…ì‹œ)
                [ê·¼ê±°] ë¶„ì„ ê·¼ê±° (êµ¬ì²´ì  í‚¤ì›Œë“œì™€ í‘œí˜„ ë°©ì‹, ì˜ë„ íŒŒì•…)
                [ì œì•ˆ] ê°œì„  ì œì•ˆ 3ê°€ì§€
                [ëŒ€ì•ˆ] ëŒ€ì•ˆ ë‹µë³€
                ì ìˆ˜: X

                ë‹µë³€: {request.text.strip()}
                """
                
                log_debug("[DEBUG] Gemini AIì— ë¶„ì„ ìš”ì²­ ì „ì†¡ ì¤‘...")
                import asyncio
                import re
                response = await asyncio.to_thread(GEMINI_MODEL.generate_content, prompt)
                result = response.text.strip()
                log_debug(f"[Gemini AI ì›ë³¸ ì‘ë‹µ]: {result}")
                log_debug(f"[DEBUG] Gemini AI ì‘ë‹µ ê¸¸ì´: {len(result)} ë¬¸ì")
                
                # ì ìˆ˜ íŒŒì‹± ì •ê·œì‹ ê°œì„ : ë‹¤ì–‘í•œ ë„ì–´ì“°ê¸°/ì½œë¡ /í•œê¸€ì ì˜¤íƒ€ í—ˆìš©
                score_match = re.search(r"ì \s*ìˆ˜\s*[:ï¼š=\-]?\s*(\d{1,3})", result)
                if score_match:
                    tf_score = float(score_match.group(1))
                    log_debug(f"[DEBUG] Gemini AI ì ìˆ˜ íŒŒì‹± ì„±ê³µ: {tf_score}")
                elif (not result) or ("429" in result) or ("QUOTA" in result) or ("ERROR" in result):
                    log_debug("[Gemini ì‘ë‹µ ë¹„ì •ìƒ, Groqë¡œ ì‹œë„]")
                    raise Exception("Gemini ì‘ë‹µ ë¹„ì •ìƒ")
                else:
                    log_debug("[DEBUG] Gemini AI ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨, í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ì¶”ì •")
                    if 'T' in result and 'F' not in result:
                        tf_score = 20
                    elif 'F' in result and 'T' not in result:
                        tf_score = 80
                    elif any(k in result for k in ['B', 'ê· í˜•', 'ì¤‘ë¦½', 'ë°¸ëŸ°ìŠ¤']):
                        tf_score = 50
                    elif 'T' in result and 'F' in result:
                        tf_score = 50
                    else:
                        log_debug(f"[Gemini AI ì˜ˆì™¸: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ] {result}")
                        raise Exception("Gemini ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ")
                    log_debug(f"[DEBUG] í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì • ì ìˆ˜: {tf_score}")
                    log_debug("[ë¶„ì„ ë¡œì§: gemini]")
                
                # ìƒì„¸ë¶„ì„ íŒŒì‹±
                def extract(tag):
                    m = re.search(rf"\[{tag}\](.*?)(?=\[|$)", result, re.DOTALL)
                    return m.group(1).strip() if m else ""
                
                detailed_analysis = extract("ë¶„ì„")
                reasoning = extract("ê·¼ê±°")
                suggestions_raw = extract("ì œì•ˆ")
                suggestions = [s.strip() for s in suggestions_raw.split("\n") if s.strip()] if suggestions_raw else []
                alternative_response = extract("ëŒ€ì•ˆ")
                tip = extract("ì‹¤ì²œíŒ")
                
                log_debug(f"[DEBUG] Gemini AI ë¶„ì„ ê²°ê³¼:")
                log_debug(f"[DEBUG] - ìƒì„¸ë¶„ì„: {detailed_analysis[:100]}...")
                log_debug(f"[DEBUG] - ê·¼ê±°: {reasoning[:100]}...")
                log_debug(f"[DEBUG] - ì œì•ˆ ê°œìˆ˜: {len(suggestions)}")
                log_debug(f"[DEBUG] - ëŒ€ì•ˆ: {alternative_response[:100]}...")
                log_debug(f"[DEBUG] - ì‹¤ì²œíŒ: {tip[:100]}...")
                
                # ëŒ€ì•ˆë‹µë³€ì´ ì—†ê±°ë‚˜ fallbackì¼ ë•Œ ëœë¤ ë¬¸êµ¬ ì¶”ê°€ (Fìš©, Tê°•/ì•½ êµ¬ë¶„)
                if (not alternative_response or alternative_response.strip() == "Gemini ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.") and (not tip or tip.strip() == ""):
                    log_debug("[DEBUG] Gemini AI ëŒ€ì•ˆ ë‹µë³€ ë¶€ì¡±, ëœë¤ ë¬¸êµ¬ ì¶”ê°€")
                    if tf_score <= 20:
                        one_liner = random.choice(get_t_strong_ment())
                    elif tf_score <= 40:
                        one_liner = random.choice(get_t_mild_ment())
                    else:
                        one_liner = random.choice(get_f_friendly_alternatives())
                    # Gemini ëŒ€ì•ˆ ì œì•ˆì´ ìˆìœ¼ë©´ ê·¸ ì•„ë˜ì— ì¶”ê°€
                    gemini_tip = tip
                    gemini_alt = extract("ëŒ€ì•ˆ")
                    merged = []
                    if gemini_tip and gemini_tip.strip() != "Gemini ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(gemini_tip.strip())
                    if gemini_alt and gemini_alt.strip() != "Gemini ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(gemini_alt.strip())
                    if merged:
                        alternative_response = one_liner + "\n" + "\n".join(merged)
                else:
                    # ì‹¤ì²œíŒ+ëŒ€ì•ˆì´ ìˆìœ¼ë©´ í•©ì³ì„œ ë°˜í™˜
                    merged = []
                    if tip and tip.strip() != "Gemini ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(tip.strip())
                    if alternative_response and alternative_response.strip() != "Gemini ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(alternative_response.strip())
                    if merged:
                        alternative_response = "\n".join(merged)
                
                # --- ìì—°ì–´ ì„±í–¥ íŒŒì‹± ë° ì ìˆ˜ ë³´ì • ---
                def parse_tendency_score(text):
                    text = text.replace(" ", "")
                    # ê°•ë„ ìš°ì„ ìˆœìœ„: ë§¤ìš°ê°•í•œ > ê°•í•œ > ì•½í•œ > ê· í˜•/ì¤‘ë¦½/ë°¸ëŸ°ìŠ¤
                    if re.search(r"ë§¤ìš°ê°•(í•œ)?Tì„±í–¥", text):
                        return 5
                    if re.search(r"ê°•(í•œ)?Tì„±í–¥", text):
                        return 15
                    if re.search(r"ì•½(í•œ)?Tì„±í–¥", text):
                        return 35
                    if re.search(r"Tì™€Fì˜ê· í˜•|ë…¼ë¦¬ì™€ê°ì •ì˜ê· í˜•|ì¤‘ë¦½|ë°¸ëŸ°ìŠ¤", text):
                        return 50
                    if re.search(r"ì•½(í•œ)?Fì„±í–¥", text):
                        return 65
                    if re.search(r"ê°•(í•œ)?Fì„±í–¥", text):
                        return 85
                    if re.search(r"ë§¤ìš°ê°•(í•œ)?Fì„±í–¥", text):
                        return 95
                    if re.search(r"Tì„±í–¥", text):
                        return 40
                    if re.search(r"Fì„±í–¥", text):
                        return 60
                    return None
                
                # ìì—°ì–´ ì„±í–¥ ì ìˆ˜ ì¶”ì¶œ
                tendency_score = parse_tendency_score(detailed_analysis)
                log_debug(f"[DEBUG] ìì—°ì–´ ì„±í–¥ ì ìˆ˜: {tendency_score}")
                # ì ìˆ˜ì™€ ìì—°ì–´ê°€ ë¶ˆì¼ì¹˜í•˜ë©´ ìì—°ì–´ ê¸°ì¤€ìœ¼ë¡œ ë³´ì •
                if tendency_score is not None and abs(tf_score - tendency_score) >= 10:
                    log_debug(f"[ì ìˆ˜/ìì—°ì–´ ë¶ˆì¼ì¹˜: Gemini ì ìˆ˜={tf_score}, ìì—°ì–´ ì ìˆ˜={tendency_score}, ìì—°ì–´ë¡œ ë³´ì •]")
                    tf_score = tendency_score
                
                log_debug(f"[DEBUG] Gemini AI ìµœì¢… ë¶„ì„ ì™„ë£Œ: ì ìˆ˜={tf_score}")
                return AnalysisResponse(
                    score=tf_score,
                    detailed_analysis=detailed_analysis,
                    reasoning=reasoning,
                    suggestions=suggestions,
                    alternative_response=alternative_response
                )
            except Exception as e:
                logger.info(f"âŒ Gemini AI ë¶„ì„ ì‹¤íŒ¨: {e}")
                log_debug(f"[Gemini AI ì˜ˆì™¸ ë°œìƒ, Groqë¡œ ì‹œë„]: {e}")
                # Gemini ì‹¤íŒ¨ ì‹œ Groqë¡œ ì‹œë„
                if AI_CLIENT:
                    try:
                        logger.info("ğŸ” Groq AI ë¶„ì„ ì‹œë„ ì¤‘...")
                        log_debug("[DEBUG] Groq AI ë¶„ì„ ë¶„ê¸° ì§„ì… (2ìˆœìœ„)")
                        prompt = f"""
                        ì•„ë˜ ë‹µë³€ì€ T(ì‚¬ê³ í˜•)ì¸ ë‚´ê°€ F(ê°ì •í˜•)ì¸ ìƒëŒ€ì—ê²Œ í•œ ë§ì´ì•¼.
                        - F(ê°ì •í˜•) ì„±í–¥ì˜ ìƒëŒ€ê°€ ì´ ë‹µë³€ì„ ë“¤ì—ˆì„ ë•Œ ì–´ë–¤ ëŠë‚Œì¼ì§€, ê·¸ë¦¬ê³  Fì—ê²Œ ë” íš¨ê³¼ì ìœ¼ë¡œ ì†Œí†µí•˜ë ¤ë©´ ì–´ë–»ê²Œ ë°”ê¾¸ë©´ ì¢‹ì„ì§€ ë¶„ì„í•´ì¤˜.
                        - ë¶„ì„ ê²°ê³¼(ìì—°ì–´)ì—ëŠ” ë°˜ë“œì‹œ 'ë§¤ìš° ê°•í•œ T ì„±í–¥', 'ê°•í•œ F ì„±í–¥', 'ì•½í•œ T ì„±í–¥', 'Tì™€ Fì˜ ê· í˜•', 'ì¤‘ë¦½', 'ë°¸ëŸ°ìŠ¤' ë“±ê³¼ ê°™ì´ 'ì„±í–¥ì´ OOOí•˜ë‹¤'ë¼ëŠ” ë¬¸êµ¬ë¥¼ ëª…í™•í•˜ê²Œ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜.
                        - ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ "ì ìˆ˜: X" í˜•ì‹ìœ¼ë¡œ 0~100 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ëª…ì‹œí•´ì¤˜. (0=ë§¤ìš° ê°•í•œ T, 50=ê· í˜•, 100=ë§¤ìš° ê°•í•œ F)
                        - ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
                        [ë¶„ì„]
                        ì„±í–¥ ë¶„ì„ ë° F ì…ì¥ì—ì„œì˜ ë°˜ì‘

                        [ê·¼ê±°]
                        ë¶„ì„ì˜ ê·¼ê±°

                        [ì œì•ˆ]
                        1. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 1
                        2. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 2
                        3. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 3

                        [ì‹¤ì²œíŒ]
                        F ì„±í–¥ ìƒëŒ€ë¥¼ ìœ„í•œ í•œ ì¤„ ì‹¤ì²œ íŒ

                        [ëŒ€ì•ˆ]
                        F ì„±í–¥ ìƒëŒ€ë¥¼ ìœ„í•œ ëŒ€ì•ˆ ë‹µë³€

                        ì ìˆ˜: X (0=ë§¤ìš° ê°•í•œ T, 50=ê· í˜•, 100=ë§¤ìš° ê°•í•œ F)

                        *** ì¤‘ìš”: ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì˜ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ***

                        ë‹µë³€: {request.text.strip()}
                        """
                        response = await AI_CLIENT.chat.completions.create(
                            messages=[{"role": "user", "content": prompt}],
                            model="llama3-8b-8192",
                        )
                        result = response.choices[0].message.content
                        if result is not None:
                            result = result.strip().upper()
                        else:
                            result = ""
                        log_debug(f"[Groq AI ì›ë³¸ ì‘ë‹µ]: {result}")
                        
                        # ì ìˆ˜ íŒŒì‹± ì •ê·œì‹ ê°œì„ : ë‹¤ì–‘í•œ ë„ì–´ì“°ê¸°/ì½œë¡ /í•œê¸€ì ì˜¤íƒ€ í—ˆìš©
                        score_match = re.search(r"ì \s*ìˆ˜\s*[:ï¼š=\-]?\s*(\d{1,3})", result)
                        if score_match:
                            tf_score = float(score_match.group(1))
                        elif (not result) or ("429" in result) or ("QUOTA" in result) or ("ERROR" in result):
                            log_debug("[Groq ì‘ë‹µ ë¹„ì •ìƒ, fallbackìœ¼ë¡œ ìì²´ ë¶„ì„ ìˆ˜í–‰]")
                            tf_score = analyze_tf_tendency(request.text)
                            log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                        else:
                            if 'T' in result and 'F' not in result:
                                tf_score = 20
                            elif 'F' in result and 'T' not in result:
                                tf_score = 80
                            elif any(k in result for k in ['B', 'ê· í˜•', 'ì¤‘ë¦½', 'ë°¸ëŸ°ìŠ¤']):
                                tf_score = 50
                            elif 'T' in result and 'F' in result:
                                tf_score = 50
                            else:
                                log_debug(f"[Groq AI ì˜ˆì™¸: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ] {result}")
                                tf_score = analyze_tf_tendency(request.text)
                                log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                            log_debug("[ë¶„ì„ ë¡œì§: groq]")
                        
                        # ìƒì„¸ë¶„ì„ íŒŒì‹±
                        def extract(tag):
                            content = response.choices[0].message.content
                            if content is None:
                                return ""
                            m = re.search(rf"\[{tag}\](.*?)(?=\[|$)", content, re.DOTALL)
                            return m.group(1).strip() if m else ""
                        
                        detailed_analysis = extract("ë¶„ì„")
                        reasoning = extract("ê·¼ê±°")
                        suggestions_raw = extract("ì œì•ˆ")
                        suggestions = [s.strip() for s in suggestions_raw.split("\n") if s.strip()] if suggestions_raw else []
                        alternative_response = extract("ëŒ€ì•ˆ")
                        tip = extract("ì‹¤ì²œíŒ")
                        
                        # ëŒ€ì•ˆë‹µë³€ì´ ì—†ê±°ë‚˜ fallbackì¼ ë•Œ ëœë¤ ë¬¸êµ¬ ì¶”ê°€ (Fìš©, Tê°•/ì•½ êµ¬ë¶„)
                        if (not alternative_response or alternative_response.strip() == "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.") and (not tip or tip.strip() == ""):
                            if tf_score <= 20:
                                one_liner = random.choice(get_t_strong_ment())
                            elif tf_score <= 40:
                                one_liner = random.choice(get_t_mild_ment())
                            else:
                                one_liner = random.choice(get_f_friendly_alternatives())
                            # Groq ëŒ€ì•ˆ ì œì•ˆì´ ìˆìœ¼ë©´ ê·¸ ì•„ë˜ì— ì¶”ê°€
                            groq_tip = tip
                            groq_alt = extract("ëŒ€ì•ˆ")
                            merged = []
                            if groq_tip and groq_tip.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                                merged.append(groq_tip.strip())
                            if groq_alt and groq_alt.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                                merged.append(groq_alt.strip())
                            if merged:
                                alternative_response = one_liner + "\n" + "\n".join(merged)
                            else:
                                alternative_response = one_liner
                        else:
                            # ì‹¤ì²œíŒ+ëŒ€ì•ˆì´ ìˆìœ¼ë©´ í•©ì³ì„œ ë°˜í™˜
                            merged = []
                            if tip and tip.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                                merged.append(tip.strip())
                            if alternative_response and alternative_response.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                                merged.append(alternative_response.strip())
                            if merged:
                                alternative_response = "\n".join(merged)
                        
                        # --- ìì—°ì–´ ì„±í–¥ íŒŒì‹± ë° ì ìˆ˜ ë³´ì • ---
                        def parse_tendency_score(text):
                            text = text.replace(" ", "")
                            # ê°•ë„ ìš°ì„ ìˆœìœ„: ë§¤ìš°ê°•í•œ > ê°•í•œ > ì•½í•œ > ê· í˜•/ì¤‘ë¦½/ë°¸ëŸ°ìŠ¤
                            if re.search(r"ë§¤ìš°ê°•(í•œ)?Tì„±í–¥", text):
                                return 5
                            if re.search(r"ê°•(í•œ)?Tì„±í–¥", text):
                                return 15
                            if re.search(r"ì•½(í•œ)?Tì„±í–¥", text):
                                return 35
                            if re.search(r"Tì™€Fì˜ê· í˜•|ë…¼ë¦¬ì™€ê°ì •ì˜ê· í˜•|ì¤‘ë¦½|ë°¸ëŸ°ìŠ¤", text):
                                return 50
                            if re.search(r"ì•½(í•œ)?Fì„±í–¥", text):
                                return 65
                            if re.search(r"ê°•(í•œ)?Fì„±í–¥", text):
                                return 85
                            if re.search(r"ë§¤ìš°ê°•(í•œ)?Fì„±í–¥", text):
                                return 95
                            if re.search(r"Tì„±í–¥", text):
                                return 40
                            if re.search(r"Fì„±í–¥", text):
                                return 60
                            return None
                        
                        # ìì—°ì–´ ì„±í–¥ ì ìˆ˜ ì¶”ì¶œ
                        tendency_score = parse_tendency_score(detailed_analysis)
                        # ì ìˆ˜ì™€ ìì—°ì–´ê°€ ë¶ˆì¼ì¹˜í•˜ë©´ ìì—°ì–´ ê¸°ì¤€ìœ¼ë¡œ ë³´ì •
                        if tendency_score is not None and abs(tf_score - tendency_score) >= 10:
                            log_debug(f"[ì ìˆ˜/ìì—°ì–´ ë¶ˆì¼ì¹˜: Groq ì ìˆ˜={tf_score}, ìì—°ì–´ ì ìˆ˜={tendency_score}, ìì—°ì–´ë¡œ ë³´ì •]")
                            tf_score = tendency_score
                        
                        return AnalysisResponse(
                            score=tf_score,
                            detailed_analysis=detailed_analysis,
                            reasoning=reasoning,
                            suggestions=suggestions,
                            alternative_response=alternative_response
                        )
                    except Exception as groq_e:
                        logger.info(f"âŒ Groq AI ë¶„ì„ ì‹¤íŒ¨: {groq_e}")
                        log_debug(f"[Groq AI ì˜ˆì™¸ ë°œìƒ, fallbackìœ¼ë¡œ ìì²´ ë¶„ì„ ìˆ˜í–‰]: {groq_e}")
                        logger.info("ğŸ” Fallback ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš© ì¤‘...")
                        tf_score = analyze_tf_tendency(request.text)
                        log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                        return AnalysisResponse(score=tf_score)
                else:
                    # Groqë„ ì—†ìœ¼ë©´ fallback
                    tf_score = analyze_tf_tendency(request.text)
                    log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                    return AnalysisResponse(score=tf_score)
        # Geminiê°€ ì—†ìœ¼ë©´ Groq ì‹œë„
        elif AI_CLIENT:
            log_debug("[DEBUG] Groq AI ë¶„ì„ ë¶„ê¸° ì§„ì… (1ìˆœìœ„)")
            try:
                prompt = f"""
                ì•„ë˜ ë‹µë³€ì€ T(ì‚¬ê³ í˜•)ì¸ ë‚´ê°€ F(ê°ì •í˜•)ì¸ ìƒëŒ€ì—ê²Œ í•œ ë§ì´ì•¼.
                - F(ê°ì •í˜•) ì„±í–¥ì˜ ìƒëŒ€ê°€ ì´ ë‹µë³€ì„ ë“¤ì—ˆì„ ë•Œ ì–´ë–¤ ëŠë‚Œì¼ì§€, ê·¸ë¦¬ê³  Fì—ê²Œ ë” íš¨ê³¼ì ìœ¼ë¡œ ì†Œí†µí•˜ë ¤ë©´ ì–´ë–»ê²Œ ë°”ê¾¸ë©´ ì¢‹ì„ì§€ ë¶„ì„í•´ì¤˜.
                - ë¶„ì„ ê²°ê³¼(ìì—°ì–´)ì—ëŠ” ë°˜ë“œì‹œ 'ë§¤ìš° ê°•í•œ T ì„±í–¥', 'ê°•í•œ F ì„±í–¥', 'ì•½í•œ T ì„±í–¥', 'Tì™€ Fì˜ ê· í˜•', 'ì¤‘ë¦½', 'ë°¸ëŸ°ìŠ¤' ë“±ê³¼ ê°™ì´ 'ì„±í–¥ì´ OOOí•˜ë‹¤'ë¼ëŠ” ë¬¸êµ¬ë¥¼ ëª…í™•í•˜ê²Œ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜.
                - ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ "ì ìˆ˜: X" í˜•ì‹ìœ¼ë¡œ 0~100 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ëª…ì‹œí•´ì¤˜. (0=ë§¤ìš° ê°•í•œ T, 50=ê· í˜•, 100=ë§¤ìš° ê°•í•œ F)
                - ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
                [ë¶„ì„]
                ì„±í–¥ ë¶„ì„ ë° F ì…ì¥ì—ì„œì˜ ë°˜ì‘

                [ê·¼ê±°]
                ë¶„ì„ì˜ ê·¼ê±°

                [ì œì•ˆ]
                1. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 1
                2. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 2
                3. Fê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ê°œì„  ì œì•ˆ 3

                [ì‹¤ì²œíŒ]
                F ì„±í–¥ ìƒëŒ€ë¥¼ ìœ„í•œ í•œ ì¤„ ì‹¤ì²œ íŒ

                [ëŒ€ì•ˆ]
                F ì„±í–¥ ìƒëŒ€ë¥¼ ìœ„í•œ ëŒ€ì•ˆ ë‹µë³€

                ì ìˆ˜: X (0=ë§¤ìš° ê°•í•œ T, 50=ê· í˜•, 100=ë§¤ìš° ê°•í•œ F)

                *** ì¤‘ìš”: ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì˜ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ***

                ë‹µë³€: {request.text.strip()}
                """
                response = await AI_CLIENT.chat.completions.create(
                    messages=[{"role": "user", "content": prompt}],
                    model="llama3-8b-8192",
                )
                result = response.choices[0].message.content
                if result is not None:
                    result = result.strip().upper()
                else:
                    result = ""
                log_debug(f"[Groq AI ì›ë³¸ ì‘ë‹µ]: {result}")
                import re
                # ì ìˆ˜ íŒŒì‹± ì •ê·œì‹ ê°œì„ : ë‹¤ì–‘í•œ ë„ì–´ì“°ê¸°/ì½œë¡ /í•œê¸€ì ì˜¤íƒ€ í—ˆìš©
                score_match = re.search(r"ì \s*ìˆ˜\s*[:ï¼š=\-]?\s*(\d{1,3})", result)
                if score_match:
                    tf_score = float(score_match.group(1))
                elif (not result) or ("429" in result) or ("QUOTA" in result) or ("ERROR" in result):
                    log_debug("[Groq ì‘ë‹µ ë¹„ì •ìƒ, fallbackìœ¼ë¡œ ìì²´ ë¶„ì„ ìˆ˜í–‰]")
                    tf_score = analyze_tf_tendency(request.text)
                    log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                else:
                    if 'T' in result and 'F' not in result:
                        tf_score = 20
                    elif 'F' in result and 'T' not in result:
                        tf_score = 80
                    elif any(k in result for k in ['B', 'ê· í˜•', 'ì¤‘ë¦½', 'ë°¸ëŸ°ìŠ¤']):
                        tf_score = 50
                    elif 'T' in result and 'F' in result:
                        tf_score = 50
                    else:
                        log_debug(f"[Groq AI ì˜ˆì™¸: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ] {result}")
                        tf_score = analyze_tf_tendency(request.text)
                        log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                    log_debug("[ë¶„ì„ ë¡œì§: groq]")
                # ìƒì„¸ë¶„ì„ íŒŒì‹±
                def extract(tag):
                    content = response.choices[0].message.content
                    if content is None:
                        return ""
                    m = re.search(rf"\[{tag}\](.*?)(?=\[|$)", content, re.DOTALL)
                    return m.group(1).strip() if m else ""
                detailed_analysis = extract("ë¶„ì„")
                reasoning = extract("ê·¼ê±°")
                suggestions_raw = extract("ì œì•ˆ")
                suggestions = [s.strip() for s in suggestions_raw.split("\n") if s.strip()] if suggestions_raw else []
                alternative_response = extract("ëŒ€ì•ˆ")
                tip = extract("ì‹¤ì²œíŒ")
                # ëŒ€ì•ˆë‹µë³€ì´ ì—†ê±°ë‚˜ fallbackì¼ ë•Œ ëœë¤ ë¬¸êµ¬ ì¶”ê°€ (Fìš©, Tê°•/ì•½ êµ¬ë¶„)
                if (not alternative_response or alternative_response.strip() == "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.") and (not tip or tip.strip() == ""):
                    if tf_score <= 20:
                        one_liner = random.choice(get_t_strong_ment())
                    elif tf_score <= 40:
                        one_liner = random.choice(get_t_mild_ment())
                    else:
                        one_liner = random.choice(get_f_friendly_alternatives())
                    # Groq ëŒ€ì•ˆ ì œì•ˆì´ ìˆìœ¼ë©´ ê·¸ ì•„ë˜ì— ì¶”ê°€
                    groq_tip = tip
                    groq_alt = extract("ëŒ€ì•ˆ")
                    merged = []
                    if groq_tip and groq_tip.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(groq_tip.strip())
                    if groq_alt and groq_alt.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(groq_alt.strip())
                    if merged:
                        alternative_response = one_liner + "\n" + "\n".join(merged)
                    else:
                        alternative_response = one_liner
                else:
                    # ì‹¤ì²œíŒ+ëŒ€ì•ˆì´ ìˆìœ¼ë©´ í•©ì³ì„œ ë°˜í™˜
                    merged = []
                    if tip and tip.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(tip.strip())
                    if alternative_response and alternative_response.strip() != "Groq ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
                        merged.append(alternative_response.strip())
                    if merged:
                        alternative_response = "\n".join(merged)
                # --- ìì—°ì–´ ì„±í–¥ íŒŒì‹± ë° ì ìˆ˜ ë³´ì • ---
                def parse_tendency_score(text):
                    text = text.replace(" ", "")
                    # ê°•ë„ ìš°ì„ ìˆœìœ„: ë§¤ìš°ê°•í•œ > ê°•í•œ > ì•½í•œ > ê· í˜•/ì¤‘ë¦½/ë°¸ëŸ°ìŠ¤
                    if re.search(r"ë§¤ìš°ê°•(í•œ)?Tì„±í–¥", text):
                        return 5
                    if re.search(r"ê°•(í•œ)?Tì„±í–¥", text):
                        return 15
                    if re.search(r"ì•½(í•œ)?Tì„±í–¥", text):
                        return 35
                    if re.search(r"Tì™€Fì˜ê· í˜•|ë…¼ë¦¬ì™€ê°ì •ì˜ê· í˜•|ì¤‘ë¦½|ë°¸ëŸ°ìŠ¤", text):
                        return 50
                    if re.search(r"ì•½(í•œ)?Fì„±í–¥", text):
                        return 65
                    if re.search(r"ê°•(í•œ)?Fì„±í–¥", text):
                        return 85
                    if re.search(r"ë§¤ìš°ê°•(í•œ)?Fì„±í–¥", text):
                        return 95
                    if re.search(r"Tì„±í–¥", text):
                        return 40
                    if re.search(r"Fì„±í–¥", text):
                        return 60
                    return None
                # ìì—°ì–´ ì„±í–¥ ì ìˆ˜ ì¶”ì¶œ
                tendency_score = parse_tendency_score(detailed_analysis)
                # ì ìˆ˜ì™€ ìì—°ì–´ê°€ ë¶ˆì¼ì¹˜í•˜ë©´ ìì—°ì–´ ê¸°ì¤€ìœ¼ë¡œ ë³´ì •
                if tendency_score is not None and abs(tf_score - tendency_score) >= 10:
                    log_debug(f"[ì ìˆ˜/ìì—°ì–´ ë¶ˆì¼ì¹˜: Groq ì ìˆ˜={tf_score}, ìì—°ì–´ ì ìˆ˜={tendency_score}, ìì—°ì–´ë¡œ ë³´ì •]")
                    tf_score = tendency_score
                return AnalysisResponse(
                    score=tf_score,
                    detailed_analysis=detailed_analysis,
                    reasoning=reasoning,
                    suggestions=suggestions,
                    alternative_response=alternative_response
                )
            except Exception as e:
                log_debug(f"[Groq AI ì˜ˆì™¸ ë°œìƒ, fallbackìœ¼ë¡œ ìì²´ ë¶„ì„ ìˆ˜í–‰]: {e}")
                tf_score = analyze_tf_tendency(request.text)
                log_debug("[ë¶„ì„ ë¡œì§: fallback]")
                return AnalysisResponse(score=tf_score)
        else:
            log_debug("[DEBUG] Fallback(í‚¤ì›Œë“œ ë¶„ì„) ë¶„ê¸° ì§„ì…")
            tf_score = analyze_tf_tendency(request.text)
            log_debug("[ë¶„ì„ ë¡œì§: fallback]")
            return AnalysisResponse(score=tf_score)
    except Exception as e:
        log_debug(f"[analyze_text ìµœìƒìœ„ ì˜ˆì™¸]: {e}")
        tf_score = analyze_tf_tendency(request.text)
        log_debug("[ë¶„ì„ ë¡œì§: fallback]")
        return AnalysisResponse(score=tf_score)

@app.post("/final_analyze")
@app.post("/api/v1/final_analyze")
async def final_analyze(request: FinalAnalysisRequest):
    logger.info(f"ğŸ” ìµœì¢… ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘... (ê²°ê³¼ ê°œìˆ˜: {len(request.results)})")
    try:
        final_result = generate_final_analysis(request.results)
        logger.info("âœ… ìµœì¢… ë¶„ì„ ì™„ë£Œ")
        return final_result
    except Exception as e:
        logger.error(f"âŒ ìµœì¢… ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate_questions")
@app.post("/api/v1/generate_questions")
async def generate_questions(request: QuestionGenerationRequest):
    """
    AI ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        questions = await generate_ai_questions_real(count=request.count or 5, difficulty=request.difficulty or "medium")
        return {
            "questions": questions,
            "count": len(questions),
            "difficulty": request.difficulty,
            "generated_by": "AI"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/questions")
@app.get("/api/v1/questions")
async def get_questions(count: int = 5):
    """
    questions.json íŒŒì¼ì—ì„œ ì§ˆë¬¸ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” ì§ˆë¬¸ ë¡œë“œ ìš”ì²­ ì²˜ë¦¬ ì¤‘... (count: {count})")
    try:
        # questions.json íŒŒì¼ ì‚¬ìš©
        questions_file = Path("question/questions.json")
        if not questions_file.exists():
            raise HTTPException(status_code=404, detail="ì§ˆë¬¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with open(questions_file, "r", encoding="utf-8") as f:
            questions_data = json.load(f)
        
        questions_list = questions_data.get("questions", [])
        
        # ìš”ì²­ëœ ê°œìˆ˜ë§Œí¼ ëœë¤ ì„ íƒ (Fisher-Yates ì…”í”Œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        import random
        if len(questions_list) > count:
            # ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…”í”Œí•œ í›„ ì•ì—ì„œë¶€í„° ì„ íƒ
            shuffled = questions_list.copy()
            random.shuffle(shuffled)
            selected_questions = shuffled[:count]
        else:
            # ì „ì²´ ë¦¬ìŠ¤íŠ¸ê°€ ìš”ì²­ ê°œìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ì „ì²´ë¥¼ ì…”í”Œí•´ì„œ ë°˜í™˜
            selected_questions = questions_list.copy()
            random.shuffle(selected_questions)
        
        return {
            "questions": selected_questions,
            "source": "questions.json",
            "count": len(selected_questions),
            "total_available": len(questions_list)
        }
            
    except json.JSONDecodeError:
        # JSON íŒŒì¼ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
        return {
            "questions": ["ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."],
            "source": "error_fallback",
            "count": 1,
            "difficulty": "medium"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/reset_log")
async def reset_log():
    try:
        with open("debug.log", "w", encoding="utf-8") as f:
            f.write("[DEBUG] ë¡œê·¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!\n")
            f.write(f"[DEBUG] ì´ˆê¸°í™” ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("[DEBUG] UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì •ìƒ ì´ˆê¸°í™”ë¨\n")
        logger.info("âœ… ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™” ì™„ë£Œ")
        return Response(content="ë¡œê·¸ ì´ˆê¸°í™” ì™„ë£Œ", media_type="text/plain")
    except Exception as e:
        logger.error(f"âŒ ë¡œê·¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¡œê·¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

def get_t_strong_ment():
    return [
        "ë¼ˆ ë§ì•˜ì–´â€¦",
        "ì–´ë””ë³´ì ë°ìŠ¤ë…¸íŠ¸ê°€...",
        "ë³µìˆ˜í•œë‹¤â€¦",
        "ë„Œ ì§„ì§œ ê°ì •ì´ë€ ê²Œ ìˆë‹ˆ?",
        "ë„Œ Dì¡Œë‹¤",
        "ì¡°ë§Œê°„ ìˆœì‚´ë§Œë“¤ì–´ì¤€ë‹¤",
        "ë¡œë´‡ì´ëƒ..?",
        "ìœ  ìŠ¤í‹¸ ë§ˆì´ ë°ìŠ¤ë…¸íŠ¸ ë„˜ë²„ì›~",
        "ìš°ë¦¬ í—¤ì–´ì ¸",
        "ì €ë¦¬ê°€ ã… ã… "
    ]

def get_t_mild_ment():
    return [
        "ê³„ì‚°ê¸°ëƒ?",
        "ë‹˜ ë°°ë ¤ì¢€...",
        "ë¡œë´‡ì´ëƒ?",
        "ì‚´ì‚´í•´ì£¼ì„¸ìš”..",
        "ë‹ˆ ë§ë„ ë§ëŠ”ë°.. ì‚´ì‚´ì¢€ ã… ",
        "ë‚´ ê¸°ë¶„ ì¡´ì¤‘ì¢€ ã… ",
        "ë§ ëŒ€ì‹  ê²°ê³¼?",
        "ê°ì •ë„ ì¢€ ì±™ê¸°ë¼êµ¬!",
        "ë„¤ ë…¼ë¦¬ ë”°ë¼ê°€ë‹¤ ë¨¸ë¦¬ í„°ì ¸ ì£½ê² ì–´",
        "íŒ©íŠ¸ë¶€í„° ì •ë¦¬í•´ë¼? ë‚´ ë§ˆìŒì€ ëˆ„ê°€ ì •ë¦¬í•´ì¤˜?"
    ]

@app.post("/stt")
@app.post("/api/v1/stt")
async def speech_to_text(audio_file: UploadFile = File(...)):
    """
    Speech to text endpoint that accepts audio file uploads
    """
    logger.info(f"ğŸ” STT ìš”ì²­ ì²˜ë¦¬ ì¤‘... (íŒŒì¼ëª…: {audio_file.filename})")
    try:
        if not audio_file:
            logger.error("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì œê³µë˜ì§€ ì•ŠìŒ")
            raise HTTPException(status_code=400, detail="No audio file provided")
        
        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        allowed_extensions = ['.wav', '.mp3', '.ogg', '.m4a']
        filename = audio_file.filename or ""
        file_ext = os.path.splitext(filename)[1].lower()
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file format. Allowed formats: {', '.join(allowed_extensions)}"
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_audio_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_audio:
                temp_audio_path = temp_audio.name
                content = await audio_file.read()
                temp_audio.write(content)
                temp_audio.flush()
                os.fsync(temp_audio.fileno())
            
            print(f"Processing audio file: {temp_audio_path}")
            # ëª¨ë“ˆí™”ëœ STT í•¨ìˆ˜ ì‚¬ìš©
            text = transcribe_audio_file(temp_audio_path)
            print(f"STT result: {text}")
            return {"text": text}
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if temp_audio_path and os.path.exists(temp_audio_path):
                try:
                    os.unlink(temp_audio_path)
                except Exception as e:
                    print(f"Failed to delete temp file: {e}")
    except Exception as e:
        print(f"STT Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/stt_enhanced")
@app.post("/api/v1/stt_enhanced")
async def speech_to_text_enhanced(audio_file: UploadFile = File(...)):
    """
    í–¥ìƒëœ STT ê¸°ëŠ¥ - ë” ì •í™•í•œ ìŒì„± ì¸ì‹ê³¼ í’ˆì§ˆ ê²€ì¦
    """
    logger.info(f"ğŸ” í–¥ìƒëœ STT ìš”ì²­ ì²˜ë¦¬ ì¤‘... (íŒŒì¼ëª…: {audio_file.filename})")
    
    try:
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        print(f"Processing audio file: {temp_file_path}")
        
        try:
            # 1ë‹¨ê³„: ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦
            quality_result = validate_audio_quality(temp_file_path)
            
            # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            if isinstance(quality_result, dict):
                for key, value in quality_result.items():
                    if hasattr(value, 'item'):  # numpy íƒ€ì…ì¸ ê²½ìš°
                        quality_result[key] = float(value)
                    elif isinstance(value, (list, dict)):
                        # ë¦¬ìŠ¤íŠ¸ë‚˜ ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ì˜ numpy íƒ€ì…ë„ ë³€í™˜
                        if isinstance(value, list):
                            quality_result[key] = [float(v) if hasattr(v, 'item') else v for v in value]
            
            # 2ë‹¨ê³„: í–¥ìƒëœ STT ì²˜ë¦¬
            stt_result = transcribe_audio_file_enhanced(temp_file_path)
            
            # 3ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬
            response_data = {
                "text": stt_result["text"],
                "original_text": stt_result["original_text"],
                "confidence": stt_result["confidence"],
                "alternatives": stt_result["alternatives"],
                "has_alternatives": stt_result["has_alternatives"],
                "audio_quality": quality_result,
                "suggestions": []
            }
            
            # 4ë‹¨ê³„: í’ˆì§ˆ ê¸°ë°˜ ì œì•ˆ ì¶”ê°€
            if not quality_result["is_good"]:
                response_data["suggestions"].extend(quality_result["suggestions"])
            
            if stt_result["confidence"] < 0.7:
                response_data["suggestions"].append("ìŒì„± ì¸ì‹ ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            
            logger.info(f"í–¥ìƒëœ STT ê²°ê³¼: '{stt_result['text']}' (ì‹ ë¢°ë„: {stt_result['confidence']:.2f})")
            
            return response_data
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except Exception as e:
        logger.error(f"í–¥ìƒëœ STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í–¥ìƒëœ STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/correct_sentence")
@app.post("/api/v1/correct_sentence")
async def correct_sentence(request: SentenceCorrectionRequest):
    """
    STT ê²°ê³¼ ë¬¸ì¥ì„ êµì •í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” ë¬¸ì¥ êµì • ìš”ì²­ ì²˜ë¦¬ ì¤‘... (í…ìŠ¤íŠ¸: {request.text})")
    
    try:
        # ë¬¸ì¥ êµì • í”„ë¡¬í”„íŠ¸ ìƒì„± (ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§€ì‹œì‚¬í•­)
        prompt = f"""
ë‹¤ìŒ ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•´ì£¼ì„¸ìš”.

êµì • ê·œì¹™:
1. ì˜¤íƒ€ë‚˜ ì˜ëª»ëœ ë‹¨ì–´ë¥¼ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¡œ ìˆ˜ì •
2. ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì • (ì¡°ì‚¬, ì–´ë¯¸ ë“±)
3. ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì™„ì„±
4. ì›ë˜ ì˜ë¯¸ëŠ” ë°˜ë“œì‹œ ìœ ì§€
5. êµì •ëœ ë¬¸ì¥ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)

ìŒì„± ì¸ì‹ ê²°ê³¼: "{request.text}"

êµì •ëœ ë¬¸ì¥:
"""
        
        # AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ êµì •
        try:
            # Gemini AI ì§ì ‘ ì‚¬ìš©
            import google.generativeai as genai
            from mbti_analyzer.config.settings import settings
            
            # Gemini AI ì„¤ì •
            import os
            gemini_key = os.getenv('GEMINI_API_KEY')
            if not gemini_key:
                # settingsì—ì„œ í™•ì¸
                gemini_key = settings.gemini_api_key
                if not gemini_key:
                    raise Exception("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            
            logger.info(f"Gemini API í‚¤ í™•ì¸: {gemini_key[:10]}...")
            genai.configure(api_key=gemini_key)
            
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # AI ì‘ë‹µ ìƒì„±
            response = model.generate_content(prompt)
            corrected_text = response.text.strip()
            
            logger.info(f"AI ì‘ë‹µ ì›ë³¸: {corrected_text}")
            
            # êµì • ê²°ê³¼ ì •ë¦¬
            if corrected_text and isinstance(corrected_text, str):
                # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
                corrected_text = corrected_text.replace("êµì •ëœ ë¬¸ì¥:", "").strip()
                corrected_text = corrected_text.replace("êµì •:", "").strip()
                corrected_text = corrected_text.replace("ìˆ˜ì •ëœ ë¬¸ì¥:", "").strip()
                corrected_text = corrected_text.replace("ê²°ê³¼:", "").strip()
                corrected_text = corrected_text.replace("ë‹µë³€:", "").strip()
                
                # ì¤„ë°”ê¿ˆ ì •ë¦¬
                corrected_text = corrected_text.replace("\n", " ").strip()
                
                # ë”°ì˜´í‘œ ì œê±°
                corrected_text = corrected_text.strip('"').strip("'").strip()
                
                # ë¹ˆ ë¬¸ìì—´ ì²´í¬
                if not corrected_text:
                    corrected_text = request.text
                
                logger.info(f"ì •ë¦¬ëœ êµì • ê²°ê³¼: '{corrected_text}'")
                
                # ì›ë³¸ê³¼ ë™ì¼í•œ ê²½ìš° ì›ë³¸ ë°˜í™˜
                has_changes = corrected_text != request.text
                
                if not has_changes:
                    logger.info("êµì • ê²°ê³¼ê°€ ì›ë³¸ê³¼ ë™ì¼í•¨")
                
                return {
                    "success": True,
                    "original_text": request.text,
                    "corrected_text": corrected_text,
                    "has_changes": has_changes,
                    "ai_response": response.text.strip()  # ë””ë²„ê¹…ìš©
                }
            else:
                raise Exception("AI ë¬¸ì¥ êµì • ìƒì„± ì‹¤íŒ¨")
                
        except Exception as ai_error:
            logger.error(f"AI ë¬¸ì¥ êµì • ì‹¤íŒ¨: {ai_error}")
            # AI ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
            return {
                "success": True,
                "original_text": request.text,
                "corrected_text": request.text,
                "has_changes": False,
                "fallback": True,
                "error": str(ai_error),
                "error_type": type(ai_error).__name__
            }
            
    except Exception as e:
        logger.error(f"ë¬¸ì¥ êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì¥ êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/correct_sentence_enhanced")
@app.post("/api/v1/correct_sentence_enhanced")
async def correct_sentence_enhanced(request: SentenceCorrectionRequest):
    """
    í–¥ìƒëœ ë¬¸ì¥ êµì • ê¸°ëŠ¥ - AIì™€ ê·œì¹™ ê¸°ë°˜ êµì •ì„ ê²°í•©
    """
    logger.info(f"ğŸ” í–¥ìƒëœ ë¬¸ì¥ êµì • ìš”ì²­ ì²˜ë¦¬ ì¤‘... (í…ìŠ¤íŠ¸: {request.text})")
    
    try:
        # ë¬¸ë§¥ ê°ì§€ (MBTI ì§ˆë¬¸ì¸ì§€ í™•ì¸)
        context = 'general'
        mbti_keywords = ['ìƒê°', 'ëŠë‚Œ', 'ê°ì •', 'ë…¼ë¦¬', 'ì‚¬ì‹¤', 'ê°ê´€', 'ì£¼ê´€']
        if any(keyword in request.text for keyword in mbti_keywords):
            context = 'mbti_question'
        
        # í–¥ìƒëœ ë¬¸ì¥ êµì • ìˆ˜í–‰
        result = correct_sentence_with_ai_enhanced(text=request.text)
        
        if result["success"]:
            logger.info(f"í–¥ìƒëœ êµì • ê²°ê³¼: '{result['corrected_text']}' (ë°©ë²•: {result['method_used']})")
            return result
        else:
            # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ êµì • ì‹œìŠ¤í…œ ì‚¬ìš©
            logger.warning("í–¥ìƒëœ êµì • ì‹¤íŒ¨, ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´")
            return await correct_sentence(request)
            
    except Exception as e:
        logger.error(f"í–¥ìƒëœ ë¬¸ì¥ êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ êµì • ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´
        return await correct_sentence(request)

@app.post("/audio_quality_check")
@app.post("/api/v1/audio_quality_check")
async def check_audio_quality(audio_file: UploadFile = File(...)):
    """
    ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦ ë° ê°œì„  ì œì•ˆ
    """
    logger.info(f"ğŸ” ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦ ìš”ì²­ ì²˜ë¦¬ ì¤‘... (íŒŒì¼ëª…: {audio_file.filename})")
    
    try:
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦
            quality_result = validate_audio_quality(temp_file_path)
            
            logger.info(f"ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ: ì ìˆ˜ {quality_result['quality_score']:.2f}")
            
            return {
                "success": True,
                "quality_score": quality_result["quality_score"],
                "duration": quality_result["duration"],
                "rms_energy": quality_result["rms_energy"],
                "issues": quality_result["issues"],
                "suggestions": quality_result["suggestions"],
                "is_good": quality_result["is_good"]
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/stt_enhancement_status")
@app.get("/api/v1/stt_enhancement_status")
async def get_stt_enhancement_status():
    """
    STT í–¥ìƒ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸
    """
    try:
        # í–¥ìƒëœ ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        enhanced_modules_available = True
        missing_modules = []
        
        try:
            from mbti_analyzer.modules.stt_module_enhanced import transcribe_audio_file_enhanced
        except ImportError:
            enhanced_modules_available = False
            missing_modules.append("stt_module_enhanced")
        
        try:
            from mbti_analyzer.modules.sentence_correction_enhanced import correct_sentence_with_ai_enhanced
        except ImportError:
            enhanced_modules_available = False
            missing_modules.append("sentence_correction_enhanced")
        
        return {
            "enhanced_features_available": enhanced_modules_available,
            "missing_modules": missing_modules,
            "available_endpoints": [
                "/stt_enhanced",
                "/correct_sentence_enhanced", 
                "/audio_quality_check"
            ] if enhanced_modules_available else [],
            "recommendations": [
                "í–¥ìƒëœ STT ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ /stt_enhanced ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”",
                "í–¥ìƒëœ ë¬¸ì¥ êµì •ì„ ì‚¬ìš©í•˜ë ¤ë©´ /correct_sentence_enhanced ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”",
                "ì˜¤ë””ì˜¤ í’ˆì§ˆì„ ë¯¸ë¦¬ í™•ì¸í•˜ë ¤ë©´ /audio_quality_check ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
            ] if enhanced_modules_available else [
                "í–¥ìƒëœ ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì„¸ìš”."
            ]
        }
        
    except Exception as e:
        logger.error(f"STT í–¥ìƒ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "enhanced_features_available": False,
            "error": str(e)
        }

# ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.post("/api/v1/learning/feedback")
async def submit_learning_feedback(request: LearningFeedbackRequest):
    """í•™ìŠµ í”¼ë“œë°± ì œì¶œ"""
    try:
        result = await learning_manager.process_user_input(
            request.question,
            request.answer,
            request.expected_score,
            request.actual_score
        )
        return {
            "success": True,
            "learning_result": result,
            "message": "í•™ìŠµ í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í•™ìŠµ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/api/v1/learning/status")
async def get_learning_status() -> LearningStatusResponse:
    """í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
    performance = learning_manager.get_recent_performance()
    return LearningStatusResponse(
        enabled=learning_manager.learning_enabled,
        total_inputs=performance["total"],
        acceptable_rate=performance["acceptable_rate"],
        average_error=performance["average_error"],
        current_version=learning_manager.current_prompt_version
    )

@app.post("/api/v1/learning/toggle")
async def toggle_learning(enabled: bool = True):
    """í•™ìŠµ ê¸°ëŠ¥ ì¼œê¸°/ë„ê¸°"""
    learning_manager.learning_enabled = enabled
    return {
        "success": True,
        "enabled": learning_manager.learning_enabled,
        "message": f"ì‹¤ì‹œê°„ í•™ìŠµì´ {'í™œì„±í™”' if enabled else 'ë¹„í™œì„±í™”'}ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.get("/api/v1/learning/history")
async def get_learning_history():
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    conn = sqlite3.connect(learning_manager.db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT question, answer, expected_score, actual_score, error, is_acceptable, timestamp, prompt_version
        FROM user_inputs
        ORDER BY timestamp DESC
        LIMIT 50
    ''')
    
    results = cursor.fetchall()
    conn.close()
    
    history = []
    for row in results:
        history.append({
            "question": row[0],
            "answer": row[1],
            "expected_score": row[2],
            "actual_score": row[3],
            "error": row[4],
            "is_acceptable": bool(row[5]),
            "timestamp": row[6],
            "prompt_version": row[7]
        })
    
    return {
        "success": True,
        "history": history,
        "total_count": len(history)
    }

@app.get("/index_with_learning.html")
async def read_index_with_learning():
    """ì‹¤ì‹œê°„ í•™ìŠµì´ í†µí•©ëœ ë©”ì¸ í˜ì´ì§€"""
    return FileResponse("index_with_learning.html")

@app.post("/tts")
@app.post("/api/v1/tts")
async def text_to_speech_endpoint(
    request: TextRequest = None, 
    text: str = Form(None),
    voice_name: str = Form('ko-KR-Chirp3-HD-Leda'),
    gender: str = Form('FEMALE'),
    speaking_rate: float = Form(1.1),
    pitch: float = Form(0.0)
):
    """
    Text to speech endpoint that converts text to audio with advanced options
    Supports both JSON and FormData requests
    """
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (JSON ë˜ëŠ” FormData)
    if request and request.text:
        text_content = request.text
    elif text:
        text_content = text
    else:
        logger.error("âŒ í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
        raise HTTPException(status_code=400, detail="No text provided")
    
    logger.info(f"ğŸ” TTS ìš”ì²­ ì²˜ë¦¬ ì¤‘... (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content)}, ìŒì„±: {voice_name}, ì„±ë³„: {gender})")
    try:
        # TTS í•¨ìˆ˜ ì‚¬ìš© (Google Cloud TTS + ê³ ê¸‰ ì˜µì…˜)
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_file_path = temp_file.name
        temp_file.close()
        
        success = text_to_speech(
            text_content, 
            temp_file_path,
            voice_name=voice_name,
            gender=gender,
            speaking_rate=speaking_rate,
            pitch=pitch
        )
        
        if not success:
            raise Exception("TTS ìƒì„± ì‹¤íŒ¨")
        
        audio_path = temp_file_path
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì‘ë‹µìœ¼ë¡œ ë°˜í™˜
        return FileResponse(
            path=audio_path,
            media_type="audio/mpeg",
            filename="speech.mp3"
        )
        
    except Exception as e:
        print(f"TTS Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def remove_tts_code():
    pass

@app.post("/correct_sentence")
@app.post("/api/v1/correct_sentence")
async def correct_sentence(request: SentenceCorrectionRequest):
    """
    STT ê²°ê³¼ ë¬¸ì¥ì„ êµì •í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” ë¬¸ì¥ êµì • ìš”ì²­ ì²˜ë¦¬ ì¤‘... (í…ìŠ¤íŠ¸: {request.text})")
    
    try:
        # ë¬¸ì¥ êµì • í”„ë¡¬í”„íŠ¸ ìƒì„± (ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§€ì‹œì‚¬í•­)
        prompt = f"""
ë‹¤ìŒ ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•´ì£¼ì„¸ìš”.

êµì • ê·œì¹™:
1. ì˜¤íƒ€ë‚˜ ì˜ëª»ëœ ë‹¨ì–´ë¥¼ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¡œ ìˆ˜ì •
2. ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì • (ì¡°ì‚¬, ì–´ë¯¸ ë“±)
3. ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì™„ì„±
4. ì›ë˜ ì˜ë¯¸ëŠ” ë°˜ë“œì‹œ ìœ ì§€
5. êµì •ëœ ë¬¸ì¥ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)

ìŒì„± ì¸ì‹ ê²°ê³¼: "{request.text}"

êµì •ëœ ë¬¸ì¥:
"""
        
        # AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ êµì •
        try:
            # Gemini AI ì§ì ‘ ì‚¬ìš©
            import google.generativeai as genai
            from mbti_analyzer.config.settings import settings
            
            # Gemini AI ì„¤ì •
            import os
            gemini_key = os.getenv('GEMINI_API_KEY')
            if not gemini_key:
                # settingsì—ì„œ í™•ì¸
                gemini_key = settings.gemini_api_key
                if not gemini_key:
                    raise Exception("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            
            logger.info(f"Gemini API í‚¤ í™•ì¸: {gemini_key[:10]}...")
            genai.configure(api_key=gemini_key)
            
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # AI ì‘ë‹µ ìƒì„±
            response = model.generate_content(prompt)
            corrected_text = response.text.strip()
            
            logger.info(f"AI ì‘ë‹µ ì›ë³¸: {corrected_text}")
            
            # êµì • ê²°ê³¼ ì •ë¦¬
            if corrected_text and isinstance(corrected_text, str):
                # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
                corrected_text = corrected_text.replace("êµì •ëœ ë¬¸ì¥:", "").strip()
                corrected_text = corrected_text.replace("êµì •:", "").strip()
                corrected_text = corrected_text.replace("ìˆ˜ì •ëœ ë¬¸ì¥:", "").strip()
                corrected_text = corrected_text.replace("ê²°ê³¼:", "").strip()
                corrected_text = corrected_text.replace("ë‹µë³€:", "").strip()
                
                # ì¤„ë°”ê¿ˆ ì •ë¦¬
                corrected_text = corrected_text.replace("\n", " ").strip()
                
                # ë”°ì˜´í‘œ ì œê±°
                corrected_text = corrected_text.strip('"').strip("'").strip()
                
                # ë¹ˆ ë¬¸ìì—´ ì²´í¬
                if not corrected_text:
                    corrected_text = request.text
                
                logger.info(f"ì •ë¦¬ëœ êµì • ê²°ê³¼: '{corrected_text}'")
                
                # ì›ë³¸ê³¼ ë™ì¼í•œ ê²½ìš° ì›ë³¸ ë°˜í™˜
                has_changes = corrected_text != request.text
                
                if not has_changes:
                    logger.info("êµì • ê²°ê³¼ê°€ ì›ë³¸ê³¼ ë™ì¼í•¨")
                
                return {
                    "success": True,
                    "original_text": request.text,
                    "corrected_text": corrected_text,
                    "has_changes": has_changes,
                    "ai_response": response.text.strip()  # ë””ë²„ê¹…ìš©
                }
            else:
                raise Exception("AI ë¬¸ì¥ êµì • ìƒì„± ì‹¤íŒ¨")
                
        except Exception as ai_error:
            logger.error(f"AI ë¬¸ì¥ êµì • ì‹¤íŒ¨: {ai_error}")
            # AI ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
            return {
                "success": True,
                "original_text": request.text,
                "corrected_text": request.text,
                "has_changes": False,
                "fallback": True,
                "error": str(ai_error),
                "error_type": type(ai_error).__name__
            }
            
    except Exception as e:
        logger.error(f"ë¬¸ì¥ êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì¥ êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

class SummarizeRequest(BaseModel):
    text: str
    type: str  # "detailed_analysis", "reasoning", "suggestions"

@app.post("/api/v1/summarize")
async def summarize_text(request: SummarizeRequest):
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” AI ìš”ì•½ ìš”ì²­ ì²˜ë¦¬ ì¤‘... (íƒ€ì…: {request.type}, í…ìŠ¤íŠ¸ ê¸¸ì´: {len(request.text)})")
    
    try:
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if request.type == "detailed_analysis":
            prompt = f"""
ë‹¤ìŒ MBTI T/F ë¶„ì„ì˜ ìƒì„¸ ë¶„ì„ ë‚´ìš©ì„ 2-3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{request.text}

ìš”ì•½ (2-3ì¤„):
"""
        elif request.type == "reasoning":
            prompt = f"""
ë‹¤ìŒ MBTI T/F ë¶„ì„ì˜ ë¶„ì„ ê·¼ê±°ë¥¼ 2-3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{request.text}

ìš”ì•½ (2-3ì¤„):
"""
        elif request.type == "suggestions":
            prompt = f"""
ë‹¤ìŒ MBTI T/F ë¶„ì„ì˜ ê°œì„  ì œì•ˆì„ 2-3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{request.text}

ìš”ì•½ (2-3ì¤„):
"""
        else:
            raise HTTPException(status_code=400, detail="Invalid type parameter")

        # AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ìƒì„±
        try:
            # Gemini AI ì‚¬ìš© (1ìˆœìœ„)
            from mbti_analyzer.core.question_generator import generate_ai_questions_real
            summary = await generate_ai_questions_real(prompt)
            
            # ìš”ì•½ ê²°ê³¼ ì •ë¦¬
            if summary and isinstance(summary, str):
                # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
                summary = summary.replace("ìš”ì•½ (2-3ì¤„):", "").strip()
                summary = summary.replace("ìš”ì•½:", "").strip()
                
                # ì¤„ë°”ê¿ˆ ì •ë¦¬
                summary = summary.replace("\n\n", "\n").replace("\n", " ")
                
                return {
                    "success": True,
                    "summary": summary,
                    "type": request.type,
                    "original_length": len(request.text),
                    "summary_length": len(summary)
                }
            else:
                raise Exception("AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
                
        except Exception as ai_error:
            logger.error(f"AI ìš”ì•½ ì‹¤íŒ¨: {ai_error}")
            # AI ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
            fallback_summary = request.text[:100] + "..." if len(request.text) > 100 else request.text
            return {
                "success": True,
                "summary": fallback_summary,
                "type": request.type,
                "original_length": len(request.text),
                "summary_length": len(fallback_summary),
                "fallback": True
            }
            
    except Exception as e:
        logger.error(f"ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    # ì„œë²„ ì‹œì‘ ì‹œ debug.log íŒŒì¼ ì´ˆê¸°í™”
    with open("debug.log", "w", encoding="utf-8") as f:
        f.write("[DEBUG] ì„œë²„ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\n")
        f.write(f"[DEBUG] ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼: {os.path.abspath(__file__)}\n")
    
    # Static íŒŒì¼ ë§ˆìš´íŠ¸
    app.mount("/", StaticFiles(directory=".", html=True), name="static")
    
    uvicorn.run(app, host="0.0.0.0", port=8000) 