"""
T/F ì„±í–¥ ë¶„ì„ ë¡œì§

í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ MBTIì˜ T(ì‚¬ê³ í˜•)/F(ê°ì •í˜•) ì„±í–¥ì„ íŒë‹¨í•˜ëŠ” í•µì‹¬ ë¡œì§ì…ë‹ˆë‹¤.
"""

import re
import logging
from typing import Dict, Optional
import google.generativeai as genai
import os
from groq import AsyncGroq

logger = logging.getLogger(__name__)

def analyze_tf_tendency(text: str) -> float:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ T, 100ì— ê°€ê¹Œìš¸ìˆ˜ë¡ F ì„±í–¥ì…ë‹ˆë‹¤.
    """
    text = text.lower()
    logger.info(f"ğŸ” Fallback ë¶„ì„ ì‹œì‘: {text[:50]}...")

    # ì‚¬ê³ í˜•(T) ê°•í•œ ë¬´ì‹¬/ë‹¨ì •/ê°ê´€ì  í‘œí˜„ íŒ¨í„´ (í™•ì‹¤í•œ ì‚¬ê³ í˜•)
    t_strong_patterns = [
        r"ì–´ì©Œë¼ê³ ", r"ìƒê´€ì—†ì–´", r"ì•Œì•„ì„œ í•´", r"ë‚´ ì•Œ ë°” ì•„ëƒ", r"ê·¸ê²Œ ë‚˜ë‘ ë¬´ìŠ¨ ìƒê´€ì´ì•¼",
        r"ë„¤ ë§ˆìŒëŒ€ë¡œ í•´", r"ë‚´ê°€ ë­˜", r"ê·¸ê±´ ë„¤ ë¬¸ì œì•¼", r"ê·¸ê±´ ì¤‘ìš”í•˜ì§€ ì•Šì•„"
    ]
    t_strong_count = sum(len(re.findall(pattern, text)) for pattern in t_strong_patterns)
    if t_strong_count > 0:
        score = max(15, 30 - (t_strong_count - 1) * 5)
        return float(score)

    # ì‹¸ê°€ì§€ ì—†ëŠ”(ê³µê° ì—†ëŠ” í‰ëª…/ë¬´ì‹¬) íŒ¨í„´ (ì‚´ì§ T)
    t_rude_patterns = [
        r"ëª°ë¼", r"ë”±íˆ", r"ë³„ ìƒê° ì—†ì–´", r"ì‹ ê²½ ì•ˆ ì¨", r"ê´€ì‹¬ ì—†ì–´", r"ê·¸ëƒ¥ ê·¸ë˜", r"ê¸€ì„", r"ìŒ[.\.\,\!\?â€¦]*$", r"ë³„ë¡œì•¼"
    ]
    t_rude_count = sum(len(re.findall(pattern, text)) for pattern in t_rude_patterns)
    if t_rude_count > 0:
        # í‰ëª…/ë¬´ì‹¬ íŒ¨í„´ì´ ê°ì§€ë˜ë©´ 35~45ì (ì‚´ì§ T)
        score = max(35, 45 - (t_rude_count - 1) * 3)
        return float(score)

    # 1. í‚¤ì›Œë“œ(í•µì‹¬/ì•½í•œ) ë° ê°€ì¤‘ì¹˜
    t_keywords_strong = [
        'ë…¼ë¦¬', 'ë¶„ì„', 'íŒë‹¨', 'íš¨ìœ¨', 'ê°ê´€', 'ì‚¬ì‹¤', 'ì¦ê±°', 'í•©ë¦¬', 'ì´ì„±', 'ì²´ê³„',
        'ì •í™•', 'ëª…í™•', 'ì¼ê´€', 'ë°ì´í„°', 'í†µê³„', 'ì¸¡ì •',
        'ë§ë‹¤', 'í‹€ë ¸ë‹¤', 'ì •ë‹µ', 'í™•ì‹¤', 'ëª…ë°±', 'ë¶„ëª…', 'í™•ì¸',
        'ê²€í† ', 'í‰ê°€', 'ê¸°ì¤€', 'ì¡°ê±´', 'í•´ê²°', 'ê°œì„ ',
        'ìµœì ', 'íš¨ê³¼', 'ê²°ì •', 'ì„ íƒ', 'ìš°ì„ ìˆœìœ„', 'ì¤‘ìš”ë„',
        'ë¶ˆê°€ëŠ¥', 'ë¬¸ì œ', 'í•´ë‹µ', 'ë‹µ', 'ë°˜ë“œì‹œ', 'ë¬´ì¡°ê±´', 'ì²´í¬', 'ì‹¤ìš©ì ', 'ê³„ì‚°'
    ]
    t_keywords_weak = [
        'ê³„íš', 'ì „ëµ', 'ëª©í‘œ', 'ì„±ê³¼', 'ë°©ë²•', 'í•´ì•¼', 'í•´ì•¼ì§€', 'í•˜ì', 'ëë‹¤', 'ì•ˆ ë¼', 'ì•ˆ ë¨',
        'í™•ì‹¤íˆ', 'ë¶„ëª…íˆ', 'ì •í™•íˆ', 'ë‹¹ì—°íˆ', 'ë°”ë¡œ', 'ë¨¼ì €', 'ìš°ì„ ', 'ì¼ë‹¨', 'ì •ë¦¬', 'íš¨ê³¼ì ', 'íš¨ìœ¨ì ',
        'ê°„ë‹¨', 'ë³µì¡', 'ê°€ëŠ¥', 'ëë‹¤', 'ìš°ì„ ', 'ì¼ë‹¨', 'í¸í•´', 'í¸ë¦¬', 'ì‰½ë‹¤', 'ì–´ë µë‹¤', 'ì‹œê°„', 'ê°€ê²©', 'ë¹„ìš©'
    ]
    f_keywords_strong = [
        'ê°ì •', 'ë§ˆìŒ', 'ê³µê°', 'ë°°ë ¤', 'ì´í•´', 'ì¡°í™”', 'í˜‘ë ¥', 'ê´€ê³„', 'ì†Œí†µ', 'ì¹œë°€',
        'ê°€ì¹˜', 'ì˜ë¯¸', 'ë„ë•', 'ìœ¤ë¦¬', 'ì§€ì›', 'ê²©ë ¤', 'í–‰ë³µ', 'ìŠ¬í”„', 'ê±±ì •', 'ë¯¸ì•ˆ', 'ê³ ë§ˆ', 'ì†Œì¤‘', 'ì‚¬ë‘',
        'ë”°ëœ»', 'í¬ê·¼', 'ì•„ëŠ‘', 'í¸ì•ˆ', 'ì•ˆì‹¬', 'ë“ ë“ ', 'ê¸°ë¶„', 'ëŠë‚Œ', 'ë§ˆìŒê°€ì§', 'ì‹¬ì •',
        'í•¨ê»˜', 'ê°™ì´', 'ì„œë¡œ', 'ìš°ë¦¬ ëª¨ë‘', 'ì¹œêµ¬', 'ê°€ì¡±', 'ì‚¬ëŒë“¤', 'ë™ë£Œë“¤',
        'ì˜ˆë»', 'ê·€ì—¬ì›Œ', 'ì°©í•´', 'ë©‹ì ¸', 'ì¢‹ì•„í•´', 'ì‹«ì–´í•´'
    ]
    f_keywords_weak = [
        'ê¸°ë»', 'ì¦ê±°ì›Œ', 'ì‹ ë‚˜', 'í–‰ë³µí•´', 'ë§Œì¡±', 'ë¿Œë“¯', 'ì†ìƒ', 'ì§œì¦', 'í™”ë‚˜', 'ë‹µë‹µ', 'ë¶ˆì•ˆ', 'ì‹ ê²½ ì“°ì—¬',
        'ìš°ë¦¬', 'ë‹¤í•¨ê»˜', 'í•¨ê»˜ í•˜ì', 'ê°™ì´ í•˜ì', 'ë§ˆìŒì—', 'ë”°ëœ»', 'í¬ê·¼', 'ë³´ê³  ì‹¶ì–´', 'ë§Œë‚˜ê³  ì‹¶ì–´', 'í•˜ê³  ì‹¶ì–´'
    ]

    # ê°€ì¤‘ì¹˜ ì ìš© ì¹´ìš´íŠ¸
    t_count = sum(2 for keyword in t_keywords_strong if keyword in text) + sum(1 for keyword in t_keywords_weak if keyword in text)
    f_count = sum(2 for keyword in f_keywords_strong if keyword in text) + sum(1 for keyword in f_keywords_weak if keyword in text)

    # íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ë¶„ì„
    f_patterns = [
        r'ì–´ë–»ê²Œ ìƒê°|ì–´ë–¤ ëŠë‚Œ|ê´œì°®ì„ê¹Œ|ì–´ë–¨ê¹Œ|ì¢‹ì„ ê²ƒ ê°™|ë‚˜ì  ê²ƒ ê°™',
        r'í•˜ë©´ ì¢‹ê² |í–ˆìœ¼ë©´|ì¸ ê²ƒ ê°™|ëŠë‚Œì´|ê¸°ë¶„ì´',
        r'í•¨ê»˜|ê°™ì´|ì„œë¡œ|ìš°ë¦¬|ëª¨ë‘|ë‹¤í•¨ê»˜',
        r'ë¯¸ì•ˆ|ê³ ë§ˆì›Œ|ì‚¬ë‘|ì†Œì¤‘|ì•„ê»´|ì±™ê¸°',
        r'ê³µê°|ì´í•´|ìœ„ë¡œ|ê²©ë ¤|ì‘ì›',
        r'ì¢‹ì•„|ì‹«ì–´|ì˜ˆë»|ê·€ì—¬ì›Œ|ì¬ë°Œ|ì§€ë£¨',
        r'ê¸°ë¶„ ì¢‹|ëŠë‚Œ ì¢‹|ë§ˆìŒì—|ë”°ëœ»|í¬ê·¼',
        r'í•˜ê³  ì‹¶ì–´|ê°€ê³  ì‹¶ì–´|ë³´ê³  ì‹¶ì–´|ë§Œë‚˜ê³  ì‹¶ì–´',
        r'ê°™ì´ í•˜ì|í•¨ê»˜ í•˜ì|ìš°ë¦¬ ëª¨ë‘|ë‹¤ ê°™ì´'
    ]
    t_patterns = [
        r'í•´ì•¼ í•œë‹¤|í•´ì•¼ì§€|í•˜ì|í•˜ë©´ ë¼|ë˜ë©´|ì•ˆ ë˜ë©´',
        r'ë‹¹ì—°íˆ|ì •í™•íˆ|ë§ë‹¤|í‹€ë ¸ë‹¤|ì˜³ë‹¤|ê·¸ë¥´ë‹¤|í™•ì‹¤íˆ|ë¶„ëª…íˆ',
        r'íš¨ìœ¨ì |ì²´ê³„ì |ë…¼ë¦¬ì |í•©ë¦¬ì |ê°ê´€ì ',
        r'ì¤‘ìš”í•œ ê±´|í•µì‹¬ì€|ë¬¸ì œëŠ”|í•´ê²°ì±…ì€|ë°©ë²•ì€',
        r'ë¨¼ì €|ìš°ì„ |ì°¨ë¡€ë¡œ|ë‹¨ê³„ë³„ë¡œ|ê³„íšì ìœ¼ë¡œ',
        r'ê·¸ëƒ¥|ë°”ë¡œ|ë¹¨ë¦¬|ì¦‰ì‹œ|ì¼ë‹¨|ìš°ì„ ',
        r'ì•ˆ ë¼|ì•ˆ ë¨|ë˜ë„¤|ëë‹¤|ê°€ëŠ¥|ë¶ˆê°€ëŠ¥',
        r'ì‰½ë‹¤|ì–´ë µë‹¤|ê°„ë‹¨|ë³µì¡|í¸í•´|í¸ë¦¬',
        r'ê³„ì‚°|ë¹„ìš©|ê°€ê²©|ì‹œê°„|íš¨ê³¼|ì‹¤ìš©'
    ]
    f_pattern_count = sum(len(re.findall(pattern, text)) for pattern in f_patterns)
    t_pattern_count = sum(len(re.findall(pattern, text)) for pattern in t_patterns)
    
    soft_tone = len(re.findall(r'ê²ƒ ê°™ì•„|ì¸ ë“¯|ì•„ë§ˆ|í˜¹ì‹œ|ë©´ ì–´ë–¨ê¹Œ|í•˜ë©´ ì¢‹ê² |~ì¸ê°€|~í• ê¹Œ|~ì§€ ì•Šì„ê¹Œ', text))
    firm_tone = len(re.findall(r'ë°˜ë“œì‹œ|ë¬´ì¡°ê±´|í™•ì‹¤íˆ|ë‹¹ì—°íˆ|ëª…ë°±íˆ|ë¶„ëª…íˆ|í•´ì•¼|í•˜ì|ëœë‹¤|ì•ˆ ëœë‹¤', text))
    question_suggestion = len(re.findall(r'\?|í• ê¹Œ|ì–´ë–¨ê¹Œ|ì¢‹ì„ê¹Œ|ì–´ë•Œ|ê´œì°®ì„ê¹Œ', text))
    statement_command = len(re.findall(r'ë‹¤\.|ì´ë‹¤\.|í•˜ì\.|í•´ì•¼\.|ëœë‹¤\.|ì•ˆ ëœë‹¤\.', text))
    
    total_keywords = t_count + f_count
    total_patterns = f_pattern_count + t_pattern_count  
    total_tone = soft_tone + firm_tone
    total_structure = question_suggestion + statement_command
    
    # 2. í‚¤ì›Œë“œ ì ìˆ˜(ê°€ì¤‘ì¹˜ ë°˜ì˜)
    if total_keywords == 0:
        keyword_score = 50
    else:
        t_ratio = t_count / total_keywords if total_keywords > 0 else 0
        f_ratio = f_count / total_keywords if total_keywords > 0 else 0
        if t_ratio > f_ratio:
            intensity = min(t_count, 4)
            keyword_score = 25 - (intensity * 7)  # ê¸°ì¡´ 30ì—ì„œ 25ë¡œ, ê°•ë„ë³„ -7ì ì”©
        elif f_ratio > t_ratio:
            intensity = min(f_count, 4)
            keyword_score = 75 + (intensity * 7)  # ê¸°ì¡´ 70ì—ì„œ 75ë¡œ, ê°•ë„ë³„ +7ì ì”©
        else:
            keyword_score = 50
    
    # 3. íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ì ìˆ˜(ë™ì /ì• ë§¤ì‹œ ê°€ì¤‘ì¹˜ ì¦ê°€)
    if total_patterns == 0:
        pattern_score = 50
    else:
        t_pattern_ratio = t_pattern_count / total_patterns
        f_pattern_ratio = f_pattern_count / total_patterns
        if t_pattern_ratio > f_pattern_ratio:
            intensity = min(t_pattern_count, 3)
            pattern_score = 30 - (intensity * 5)
        elif f_pattern_ratio > t_pattern_ratio:
            intensity = min(f_pattern_count, 3)
            pattern_score = 70 + (intensity * 5)
        else:
            pattern_score = 50
    
    if total_tone == 0:
        tone_score = 50
    else:
        if firm_tone > soft_tone:
            intensity = min(firm_tone, 2)
            tone_score = 25 - (intensity * 5)
        elif soft_tone > firm_tone:
            intensity = min(soft_tone, 2)
            tone_score = 75 + (intensity * 5)
        else:
            tone_score = 50
    
    if total_structure == 0:
        structure_score = 50
    else:
        if statement_command > question_suggestion:
            structure_score = 30
        elif question_suggestion > statement_command:
            structure_score = 70
        else:
            structure_score = 50
    
    text_length = len(text.replace(' ', ''))
    # ë™ì /ì• ë§¤í• ìˆ˜ë¡ íŒ¨í„´/ì–´ì¡°/êµ¬ì¡° ê°€ì¤‘ì¹˜ ì¦ê°€
    if total_keywords == 0 or abs(t_count - f_count) <= 2:
        keyword_weight = 0.25
        pattern_weight = 0.3
        tone_weight = 0.25
        structure_weight = 0.2
    elif text_length < 15:
        keyword_weight = 0.5
        pattern_weight = 0.2  
        tone_weight = 0.15
        structure_weight = 0.15
    elif text_length < 30:
        keyword_weight = 0.45
        pattern_weight = 0.25
        tone_weight = 0.2
        structure_weight = 0.1
    else:
        keyword_weight = 0.4
        pattern_weight = 0.3
        tone_weight = 0.2
        structure_weight = 0.1
    
    # 4. ìµœì¢… ì ìˆ˜ ê³„ì‚°
    final_score = (
        keyword_score * keyword_weight +
        pattern_score * pattern_weight +
        tone_score * tone_weight +
        structure_score * structure_weight
    )
    
    # 5. ì ìˆ˜ ë²”ìœ„ ì œí•œ (15~85)
    final_score = max(15, min(85, final_score))
    
    logger.info(f"ğŸ” Fallback ë¶„ì„ ì™„ë£Œ: {final_score}ì ")
    return float(final_score)

async def analyze_with_gemini(text: str) -> Optional[Dict]:
    """Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ T/F ì„±í–¥ ë¶„ì„ (ver02 ìŠ¤íƒ€ì¼ ìƒì„¸ ë¶„ì„)"""
    logger.info("ğŸ” Gemini AI ë¶„ì„ ì‹œì‘")
    logger.info(f"ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
    
    try:
        # 1. API í‚¤ í™•ì¸
        logger.info("ğŸ”‘ Gemini API í‚¤ í™•ì¸ ì¤‘...")
        gemini_key = os.getenv('GEMINI_API_KEY')
        if not gemini_key:
            from mbti_analyzer.config.settings import settings
            gemini_key = settings.gemini_api_key
            logger.info("í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì°¾ì§€ ëª»í•´ ì„¤ì • íŒŒì¼ì—ì„œ í™•ì¸")
        
        if not gemini_key:
            logger.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.error("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” settings.gemini_api_keyë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return None
        
        logger.info("âœ… Gemini API í‚¤ í™•ì¸ ì™„ë£Œ")
        
        # 2. Gemini AI ëª¨ë¸ ì´ˆê¸°í™”
        logger.info("ğŸ¤– Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        logger.info("âœ… Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± (ver02 ìŠ¤íƒ€ì¼ ìƒì„¸ ë¶„ì„)
        logger.info("ğŸ“ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        prompt = f"""
MBTI T/F ì„±í–¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ì„ í‰ê°€í•˜ì„¸ìš”.

[ë¶„ì„ ê¸°ì¤€]
- T(Thinking): ë…¼ë¦¬ì , ê°ê´€ì , ë¶„ì„ì  ì‚¬ê³ , ì›ì¸ ë¶„ì„, ì²´ê³„ì  ì ‘ê·¼, íš¨ìœ¨ì„± ì¤‘ì‹œ, ë¬¸ì œ í•´ê²° ì§€í–¥
- F(Feeling): ê°ì •ì , ê³µê°ì , ê´€ê³„ ì¤‘ì‹¬ì  ì‚¬ê³ , ê¸°ë¶„ ê³ ë ¤, ê³µê° í‘œí˜„, ê´€ê³„ ì¤‘ì‹œ, ê°ì •ì  ì§€ì§€
- ì ìˆ˜: 0(ë§¤ìš° ê°•í•œ T) ~ 100(ë§¤ìš° ê°•í•œ F), 50=ê· í˜•

[í•µì‹¬ ë¶„ì„ ì›ì¹™]
1. ë‹µë³€ì˜ ì£¼ìš” ì˜ë„ì™€ í•µì‹¬ ë©”ì‹œì§€ì— ì§‘ì¤‘
2. T ì„±í–¥ ê°•í•œ í‘œí˜„: "ë¶„ì„", "ì›ì¸", "ë…¼ë¦¬", "ì²´ê³„", "íš¨ìœ¨", "ë°©ì§€", "íŒŒì•…", "ê²°ê³¼", "í•´ê²°", "ì ‘ê·¼", "ë‹¨ê³„ë³„", "ì²´ê³„ì "
3. F ì„±í–¥ ê°•í•œ í‘œí˜„: "ê¸°ë¶„", "ë§ˆìŒ", "ê³µê°", "í˜ë“¤", "ì•ˆíƒ€ê¹", "ê¶ê¸ˆ", "ë„ì™€", "í•¨ê»˜", "ì§€ì§€", "ìœ„ë¡œ", "ê±±ì •", "ì•ˆíƒ€ê¹"
4. í˜¼í•© ë‹µë³€ ë¶„ì„: 
   - T+F í˜¼í•© ë‹µë³€ì˜ ê²½ìš°: í•µì‹¬ ë©”ì‹œì§€ì˜ ë°©í–¥ì„±ì— ë”°ë¼ íŒë‹¨
   - "ë¶„ì„í•˜ì" + "ìì±…í•˜ì§€ ë§ˆ" â†’ T ì„±í–¥ì´ ìš°ì„  (40-60ì )
   - "í•¨ê»˜ ìƒê°í•´ë³´ì" â†’ F ì„±í–¥ì´ ìš°ì„  (60-80ì )
5. ë§¥ë½ë³„ ì ìˆ˜ ê°€ì´ë“œ:
   - ìˆœìˆ˜ T ì„±í–¥ (ë…¼ë¦¬ì  í•´ê²°): 20-40ì 
   - T+F í˜¼í•© (ë¶„ì„+ê³µê°): 40-70ì   
   - ìˆœìˆ˜ F ì„±í–¥ (ê°ì •ì  ì§€ì§€): 70-90ì 

[ì¶œë ¥ í˜•ì‹]
[ë¶„ì„] ë‹µë³€ìì˜ T/F ì„±í–¥ ë¶„ì„ (ì„±í–¥ ê°•ë„ì™€ ì£¼ìš” íŠ¹ì§• ëª…ì‹œ)
[ê·¼ê±°] ë¶„ì„ ê·¼ê±° (êµ¬ì²´ì  í‚¤ì›Œë“œì™€ í‘œí˜„ ë°©ì‹, ì˜ë„ íŒŒì•…)
[ì œì•ˆ] ê°œì„  ì œì•ˆ 3ê°€ì§€
[ëŒ€ì•ˆ] ëŒ€ì•ˆ ë‹µë³€
ì ìˆ˜: X

ë‹µë³€: {text}
"""
        logger.info("âœ… ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"ğŸ“‹ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        # 4. Gemini AI API í˜¸ì¶œ
        logger.info("ğŸš€ Gemini AI API í˜¸ì¶œ ì‹œì‘...")
        response = model.generate_content(prompt)
        logger.info("âœ… Gemini AI API í˜¸ì¶œ ì™„ë£Œ")
        
        # 5. ì‘ë‹µ ê²€ì¦
        logger.info("ğŸ” Gemini AI ì‘ë‹µ ê²€ì¦ ì¤‘...")
        if not response:
            logger.error("âŒ Gemini AI ì‘ë‹µì´ Noneì…ë‹ˆë‹¤.")
            return None
            
        if not response.text:
            logger.error("âŒ Gemini AI ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
        
        response_text = response.text.strip()
        logger.info(f"ğŸ“„ ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(response_text)} ë¬¸ì")
        logger.info(f"ğŸ“„ ì‘ë‹µ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {response_text[:200]}...")
        
        # 6. ì ìˆ˜ ì¶”ì¶œ (ver02 ìŠ¤íƒ€ì¼ ê°œì„ ëœ íŒŒì‹±)
        logger.info("ğŸ”¢ ì ìˆ˜ ì¶”ì¶œ ì¤‘...")
        import re
        
        # ì ìˆ˜ íŒŒì‹± ì •ê·œì‹ ê°œì„ : ë‹¤ì–‘í•œ ë„ì–´ì“°ê¸°/ì½œë¡ /í•œê¸€ì ì˜¤íƒ€ í—ˆìš©
        score_match = re.search(r"ì \s*ìˆ˜\s*[:ï¼š=\-]?\s*(\d{1,3})", response_text)
        if score_match:
            score = float(score_match.group(1))
            logger.info(f"âœ… ì ìˆ˜ ì¶”ì¶œ ì„±ê³µ: {score}")
            
            # ìƒì„¸ë¶„ì„ íŒŒì‹± (ver02 ìŠ¤íƒ€ì¼)
            def extract(tag):
                m = re.search(rf"\[{tag}\](.*?)(?=\[|$)", response_text, re.DOTALL)
                return m.group(1).strip() if m else ""
            
            detailed_analysis = extract("ë¶„ì„")
            reasoning = extract("ê·¼ê±°")
            suggestions_raw = extract("ì œì•ˆ")
            suggestions = [s.strip() for s in suggestions_raw.split("\n") if s.strip()] if suggestions_raw else []
            alternative_response = extract("ëŒ€ì•ˆ")
            
            logger.info(f"âœ… ìƒì„¸ë¶„ì„ íŒŒì‹± ì™„ë£Œ:")
            logger.info(f"ğŸ“‹ ìƒì„¸ë¶„ì„: {detailed_analysis[:50]}...")
            logger.info(f"ğŸ” ë¶„ì„ê·¼ê±°: {reasoning[:50]}...")
            logger.info(f"ğŸ’¡ ê°œì„ ì œì•ˆ ê°œìˆ˜: {len(suggestions)}")
            logger.info(f"ğŸ”„ ëŒ€ì•ˆë‹µë³€: {alternative_response[:50]}...")
            
            # ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
            return {
                "score": score,
                "detailed_analysis": detailed_analysis,
                "reasoning": reasoning,
                "suggestions": suggestions,
                "alternative_response": alternative_response
            }
        else:
            logger.error("âŒ ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: ì ìˆ˜ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logger.error(f"ğŸ“„ ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ Gemini AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.error(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        logger.error(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
        return None

async def analyze_with_groq(text: str) -> Optional[float]:
    """Groq AIë¥¼ ì‚¬ìš©í•˜ì—¬ T/F ì„±í–¥ ë¶„ì„"""
    try:
        groq_key = os.getenv('GROQ_API_KEY')
        if not groq_key:
            from mbti_analyzer.config.settings import settings
            groq_key = settings.groq_api_key
        
        if not groq_key:
            logger.warning("Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        client = AsyncGroq(api_key=groq_key)
        
        prompt = f"""
ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ MBTIì˜ T(ì‚¬ê³ í˜•)/F(ê°ì •í˜•) ì„±í–¥ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
- T(ì‚¬ê³ í˜•): ë…¼ë¦¬ì , ê°ê´€ì , ë¶„ì„ì , íš¨ìœ¨ì„± ì¤‘ì‹œ
- F(ê°ì •í˜•): ê°ì •ì , ê³µê°ì , ê´€ê³„ ì¤‘ì‹œ, ê°€ì¹˜ ê¸°ë°˜

í…ìŠ¤íŠ¸: "{text}"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
<TENDENCY>ì ìˆ˜</TENDENCY>
<REASONING>ë¶„ì„ ê·¼ê±°</REASONING>

ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ìˆ«ìë¡œ, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ T ì„±í–¥, 100ì— ê°€ê¹Œìš¸ìˆ˜ë¡ F ì„±í–¥ì…ë‹ˆë‹¤.
"""
        
        response = await client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=500
        )
        
        response_text = response.choices[0].message.content.strip()
        
        # ì ìˆ˜ ì¶”ì¶œ
        import re
        tendency_match = re.search(r'<TENDENCY>(\d+(?:\.\d+)?)</TENDENCY>', response_text)
        if tendency_match:
            score = float(tendency_match.group(1))
            return score
        
        return None
        
    except Exception as e:
        logger.error(f"Groq AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

async def analyze_text(text: str) -> Dict:
    """í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ T/F ì„±í–¥ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    logger.info("=" * 50)
    logger.info("ğŸš€ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘")
    logger.info(f"ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸: {text.strip()}")
    logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text.strip())} ë¬¸ì")
    
    # 1. Gemini AI ì‹œë„
    logger.info("ğŸ” 1ë‹¨ê³„: Gemini AI ë¶„ì„ ì‹œë„ ì¤‘...")
    try:
        gemini_result = await analyze_with_gemini(text)
        if gemini_result is not None:
            logger.info(f"âœ… Gemini AI ë¶„ì„ ì„±ê³µ: {gemini_result}")
            logger.info("ğŸ¯ Gemini AIë¡œ ë¶„ì„ ì™„ë£Œ")
            return {
                "score": gemini_result["score"],
                "method": "gemini",
                "success": True,
                "detailed_analysis": gemini_result.get("detailed_analysis"),
                "reasoning": gemini_result.get("reasoning"),
                "suggestions": gemini_result.get("suggestions"),
                "alternative_response": gemini_result.get("alternative_response")
            }
        else:
            logger.warning("âš ï¸ Gemini AI ë¶„ì„ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤.")
            logger.warning("âš ï¸ ë‹¤ìŒ ë‹¨ê³„(Groq AI)ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ Gemini AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.error(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        logger.error(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
        logger.warning("âš ï¸ ë‹¤ìŒ ë‹¨ê³„(Groq AI)ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # 2. Groq AI ì‹œë„
    logger.info("ğŸ” 2ë‹¨ê³„: Groq AI ë¶„ì„ ì‹œë„ ì¤‘...")
    try:
        groq_result = await analyze_with_groq(text)
        if groq_result is not None:
            logger.info(f"âœ… Groq AI ë¶„ì„ ì„±ê³µ: {groq_result}")
            logger.info("ğŸ¯ Groq AIë¡œ ë¶„ì„ ì™„ë£Œ")
            return {
                "score": groq_result,
                "method": "groq",
                "success": True
            }
        else:
            logger.warning("âš ï¸ Groq AI ë¶„ì„ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤.")
            logger.warning("âš ï¸ ë‹¤ìŒ ë‹¨ê³„(Fallback)ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ Groq AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.warning("âš ï¸ ë‹¤ìŒ ë‹¨ê³„(Fallback)ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # 3. Fallback ë¶„ì„
    logger.info("ğŸ” 3ë‹¨ê³„: Fallback ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš© ì¤‘...")
    try:
        fallback_score = analyze_tf_tendency(text)
        logger.info(f"âœ… Fallback ë¶„ì„ ì„±ê³µ: {fallback_score}")
        logger.info("ğŸ¯ Fallbackìœ¼ë¡œ ë¶„ì„ ì™„ë£Œ")
        return {
            "score": fallback_score,
            "method": "fallback",
            "success": True
        }
    except Exception as e:
        logger.error(f"âŒ Fallback ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.error("âŒ ëª¨ë“  ë¶„ì„ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return {
            "score": 50.0,  # ê¸°ë³¸ê°’
            "method": "error",
            "success": False
        } 